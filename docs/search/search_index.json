{"docs":[{"location":"/paradox.json","text":"","title":""},{"location":"/actor/shutdown.html","text":"","title":"怎样优雅的关闭 ActorSystem"},{"location":"/actor/shutdown.html#怎样优雅的关闭-actorsystem","text":"TODO","title":"怎样优雅的关闭 ActorSystem"},{"location":"/actor/discovery.html","text":"","title":"发现其它actor"},{"location":"/actor/discovery.html#发现其它actor","text":"TODO","title":"发现其它actor"},{"location":"/index.html","text":"","title":"Akka Cookbook"},{"location":"/index.html#akka-cookbook","text":"提供清晰、实用的 Akka 应用指导\n在线阅读：https://www.yangbajing.me/akka-cookbook/ 。\n从Akka 2.6开始，Typed 已经作为默认实现，本书也将基于 typed actor 讲解有关Akka的各种知识。同时，本书示例都将使用 Scala 2.13 完成。可以在 https://github.com/yangbajing/akka-cookbook 找到本书的所有示例及源文件。","title":"Akka Cookbook"},{"location":"/index.html#目录","text":"介绍 HelloWorld Behavior ActorRef 构造 ActorSystem Actor 请求-响应模式 适配响应类型到 actor actor之间使用ask（请求-响应模式） Actor外使用ask（请求-响应模式） 通过 ActorSystem 创建 actor 将 Future 结果发送给自己 创建子 actor TimerScheduler 发送消息 行为切换与状态机 StashBuffer 暂存待处理消息 处理 actor 异常 监视 actor 的停止状态 怎样向上冒泡异常 怎样优雅的停止actor Actor 生命周期 Akka 流（Streams） 介绍 深入 Source 物化与物化值 深入 Flow 深入 Sink 创建 Source 的常用函数 执行转换的 Flow 常用函数 汇聚数据的 Sink 常用函数 Streams 分组 基于时间的处理 访问文件 访问FTP/sFTP 自定义图（Graph） 访问存储 使用JDBC访问关系数据库 访问 Cassandra 访问 MongoDB 访问 Elasticsearch 集成 在 Spring 里使用 Akka Streams Akka HTTP Akka gRPC gRPC服务 构建工具 部署 PowerApi 小结 Akka 集群 使用Jackson作为序列化 Akka 持久化","title":"目录"},{"location":"/introduction.html","text":"","title":"介绍"},{"location":"/introduction.html#介绍","text":"Akka Typed Actor从2.4开始直到2.5可以商用，进而Akka 2.6已经把Akka Typed Actor做为推荐的Actor使用模式。Typed Actor与原先的Untyped Actor最大且直观的区别就是ActorRef有类型了，其签名也改成了akka.actor.typed.ActorRef[T]。","title":"介绍"},{"location":"/introduction.html#helloworld","text":"第一个示例是一个 Ping-Pong，从一个actor发送消息到另一个actor，并收到回复。\nobject Ping {\n  sealed trait Command\n  final case object Start extends Command\n  final case class PongCommand(message: String) extends Command\n  def apply(): Behavior[Command] = Behaviors.receive {\n    case (context, Start) =>\n      val pong = context.spawn(Pong(), \"pong\")\n      pong ! Pong.PingCommand(\"Scala\", context.self)\n      context.log.info(\"Started Pong actor and send message complete.\")\n      Behaviors.same\n    case (context, PongCommand(message)) =>\n      context.log.info(s\"Receive pong message: $message\")\n      Behaviors.stopped\n  }\n}\n\nobject Pong {\n  sealed trait Command\n  final case class PingCommand(message: String, replyTo: ActorRef[Ping.Command])\n      extends Command\n  def apply(): Behavior[Command] = Behaviors.receive[Command] {\n    case (context, PingCommand(message, replyTo)) =>\n      context.log.info(s\"Receive ping message: $message\")\n      replyTo ! Ping.PongCommand(s\"Hello $message\")\n      Behaviors.stopped\n  }\n}\n运行actor需要有一个ActorSystem，这面的代码将执行这个示例。\nval system: ActorSystem[Ping.Command] = ActorSystem(Ping(), \"helloworld\")\nsystem ! Ping.Start\nsystem.terminate()\n运行示例程序，可看到如何输出：\nsbt:akka-cookbook> cookbook-actor/runMain cookbook.actor.introduction.HelloWorld\n[info] running (fork) cookbook.actor.introduction.HelloWorld \n[2019-11-19 19:24:39,285] [INFO] [akka.event.slf4j.Slf4jLogger] [helloworld-akka.actor.default-dispatcher-3] [] - Slf4jLogger started\n[2019-11-19 19:24:39,374] [INFO] [cookbook.actor.introduction.Ping$] [helloworld-akka.actor.default-dispatcher-3] [akka://helloworld/user] - Started Pong actor and send message complete.\n[2019-11-19 19:24:39,374] [INFO] [cookbook.actor.introduction.Pong$] [helloworld-akka.actor.default-dispatcher-6] [akka://helloworld/user/pong] - Receive ping message: Scala\n[2019-11-19 19:24:39,375] [INFO] [cookbook.actor.introduction.Ping$] [helloworld-akka.actor.default-dispatcher-3] [akka://helloworld/user] - Receive pong message: Hello Scala\n[success] Total time: 1 s, completed Nov 19, 2019 19:24:39 PM","title":"HelloWorld"},{"location":"/introduction.html#behavior","text":"Akka Typed不再需要通过类的形式来实现Actor接口定义，而是函数的形式来定义actor。可以看到，定义的actor类型为Behavior[T]（形为），通过Behaviors.receiveMessage[T](T => Behavior[T]): Receive[T]函数来处理接收到的消息，而Receive继承了Behavior trait。通过函数签名可以看到，每次接收到消息并对其处理完成后，都必须要返回一个新的形为。\napply(): Behavior[Command]函数签名里的范性参数类型Command限制了这个actor将只接收Command或Command子类型的消息，编译器将在编译期对传给actor的消息做类型检查，相对于从前的untyped actor可以向actor传入任何类型的消息，这可以限制的减少程序中的bug。特别是在程序规模很大，当你定义了成百上千个消息时。\n也因为有类型的actor，在Akka Typed中没有了隐式发送的sender: ActorRef，必须在发送的消息里面包含回复字段，就如PingCommand消息定义里的replyTo: ActorRef[Ping.Command]字段一样。actor在处理完消息后可以通过它向发送者回复处理结果。","title":"Behavior"},{"location":"/introduction.html#actorref","text":"ActorRef[T]是Behavior[T]被ActorSystem构造后创建的actor的引用，与经典ActorRef的区别显而易见，它拥有了一个类型参数T，T限定了这个actor只能处理T或它的子类型。这相对经典actor是一大进步，特别是在你的actor系统规模很大时，若没有一个静态的类型约束你将十之八九会迷失在消息的海洋……","title":"ActorRef"},{"location":"/introduction.html#构造-actorsystem","text":"ActorSystem构造至少需要转入两个参数：\nguardianBehavior: Behavior[T]：守卫行为，它将被创建为守卫actor，其 ActorPath 地址为：akka://helloworld/user。 name: String：ActorSystem名字，这个名字除了在日志线程中显示外，在Akka Cluster时也很重要，用于标识同一个集群。","title":"构造 ActorSystem"},{"location":"/actor/index.html","text":"","title":"Actor"},{"location":"/actor/index.html#actor","text":"请求-响应模式 适用范围 问题 适配响应类型到 actor 适用范围 问题 actor之间使用ask（请求-响应模式） 适用范围 问题 完整代码 Actor外使用ask（请求-响应模式） 适用范围 问题 通过 ActorSystem 创建 actor 使用 SpawnProtocol 为守卫actor提供自定义 Spawn 消息 将 Future 结果发送给自己 适用范围 问题 创建子 actor TimerScheduler 发送消息 设置默认消息超时时间 actor定时发送消息给自己 行为切换与状态机 StashBuffer 暂存待处理消息 处理 actor 异常 监管策略 错误（Validation Error）与失败（Failure） 示例 监管树 监视 actor 的停止状态 怎样向上冒泡异常 示例代码 怎样优雅的停止actor 返回 Behaviors.stopped Graceful Stop Actor 生命周期\nTODO\ndiscovery shutdown","title":"Actor"},{"location":"/actor/request-response.html","text":"","title":"请求-响应模式"},{"location":"/actor/request-response.html#请求-响应模式","text":"请求-响应是很经典的一个模式，Ping-Pong就是一个典型的请求响应模式的应用。其完整代码如下：\nsealed trait Command\nfinal case object Start extends Command\nfinal case class PongCommand(message: String) extends Command\ndef apply(): Behavior[Command] = Behaviors.receive {\n  case (context, Start) =>\n    val pong = context.spawn(Pong(), \"pong\")\n    pong ! Pong.PingCommand(\"Scala\", context.self)\n    context.log.info(\"Started Pong actor and send message complete.\")\n    Behaviors.same\n  case (context, PongCommand(message)) =>\n    context.log.info(s\"Receive pong message: $message\")\n    Behaviors.stopped\n}","title":"请求-响应模式"},{"location":"/actor/request-response.html#适用范围","text":"订阅actor并希望收到被订阅actor响应的多个消息","title":"适用范围"},{"location":"/actor/request-response.html#问题","text":"响应消息也许不匹配请求actor的类型限制，（参阅：适配响应 获取解决方案） 很难检测到请求是否送达或已被处理 当请求actor发起多次请求时，不能保存请求上下文信息（可在消息内加上请求id或引入新的独立接收者可解决此问题）","title":"问题"},{"location":"/actor/adapted-response.html","text":"","title":"适配响应类型到 actor"},{"location":"/actor/adapted-response.html#适配响应类型到-actor","text":"通常情况下，发送actor的消息类型与接收actor的响应消息类型不匹配（不然就会退化成大部分actor都继承同一个trait，这样就失去了 Typed 的意义！）。这种情况下，我们提供一个正确类型的ActorRef[T]，并将接收actor返回的响应消息T包装成发送actor可以处理的类型。\n先定义一个消息包装类：\nsealed trait Command\nprivate final case class WrappedBackendResponse(response: Backend.Response)\n    extends Command\n消息适配器代码：\nval backendAdapter =\n  context.messageAdapter[Backend.Response](resp => WrappedBackendResponse(resp))\n应该为不同的消息类型注册独立的消息适配器，同一个消息类型多次注册的消息适配器只有最后一个生效。\n如果响应的消息类与给定消息适配器匹配或是其消息适配器消息类型的子类型，则使用它。若有多个消息适配器符合条件，则将选用最后注册的那个。\n消息适配器（context.messageAdapter返回的ActorRef[T]）的生命周期同context所在actor。建议在Behaviors.step或AbstractBehavior构造函数中注册适配器，但也可以在稍后注册它们。\n注册适配器时提供的消息映射函数（resp => WrappedBackendResponse(resp)）在actor中运行，可安全的访问其（actor）内部状态。 但注意不能抛出异常，否则actor将被停止！","title":"适配响应类型到 actor"},{"location":"/actor/adapted-response.html#适用范围","text":"在不同的actor消息协议间进行转换 订阅响应消息的actor，并将响应转换成发送actor可接收的类型","title":"适用范围"},{"location":"/actor/adapted-response.html#问题","text":"难以检测消息是否送达或已被处理 每个响应消息只能进行一次自适应，如果注册了新的适配器则旧的将被替换。如果不同的目标actor使用相同的响应类型，则它们自动选择哪个适配器更合适。这需要在消息中编码某种相关性来解决 除非协议已经包含提供上下文的方法，例如在响应中返回发送的请求ID。否则交互就不能绑定到某个上下文中。","title":"问题"},{"location":"/actor/actor-inside-ask.html","text":"","title":"actor之间使用ask（请求-响应模式）"},{"location":"/actor/actor-inside-ask.html#actor之间使用ask-请求-响应模式-","text":"当请求与响应之间存在1:1映射时，可以通过调用ActorContext[T]上的ask函数来与另一个actor进行交互。\n构造一个传出消息，它使用context.ask[Response]提供的ActorRef[Response]作为接收响应的actor放入消息中将成功/失败（Try[Response]）转换为发送者actor可接收的消息类型\nobject Ping {\n  sealed trait Request\n  private final case class WrappedResponse(response: Pong.Response) extends Request\n  def apply(latch: CountDownLatch): Behavior[Request] = Behaviors.setup { context =>\n    implicit val timeout: Timeout = 2.seconds\n    val pong = context.spawn(Pong(), \"pong\")\n    context.watch(pong)\n    context.ask(\n      pong,\n      (replyTo: ActorRef[Pong.Response]) =>\n        Pong.Message(\"Hello Scala!\", 1, replyTo)) {\n      case Success(value)     => WrappedResponse(value)\n      case Failure(exception) => throw exception\n    }\n\n    Behaviors\n      .receiveMessage[Request] {\n        case WrappedResponse(Pong.Result(message, count)) =>\n          context.log.info(s\"Received pong response: $message, ${count}th.\")\n          context.ask[Pong.Request, Pong.Response](\n            pong,\n            Pong.Message(message, count + 1, _)) {\n            case Success(value)     => WrappedResponse(value)\n            case Failure(exception) => throw exception\n          }\n          Behaviors.same\n      }\n      .receiveSignal {\n        case (_, Terminated(`pong`)) =>\n          context.log.info(s\"Actor $pong be terminated.\")\n          latch.countDown()\n          Behaviors.stopped\n      }\n  }\n}\ncontext.ask的响应映射函数在接收actor中运行，可以安全的访问actor内部状态， 但抛出异常的话actor将会被停止 。\noverride def ask[Req, Res](target: RecipientRef[Req], createRequest: ActorRef[Res] => Req)(\n      mapResponse: Try[Res] => T)(implicit responseTimeout: Timeout, classTag: ClassTag[Res]): Unit = {\n    import akka.actor.typed.scaladsl.AskPattern._\n    pipeToSelf((target.ask(createRequest))(responseTimeout, system.scheduler))(mapResponse)\n  }\n\n  def pipeToSelf[Value](future: Future[Value])(mapResult: Try[Value] => T): Unit = {\n    future.onComplete(value => self.unsafeUpcast ! AdaptMessage(value, mapResult))\n  }\n上面是context.ask函数实现：\ntarget：接收actor引用 createRequest：创建请求消息函数，参数是ask创建的临时actor，此临时actor用于适配接收actor的消息类型 mapResponse：将获取的响应消息类型Res映射成请求actor可以接收的消息类型\n可以看到，context.ask函数实际上是在目标actor（target）上调用了ask方法，并将返回的Future[T]结果转换并发送到context所在的actor。","title":"actor之间使用ask（请求-响应模式）"},{"location":"/actor/actor-inside-ask.html#适用范围","text":"单个查询响应的转换 发送actor需要在继续之前知道消息已被处理（通过context.ask(..., ...)(mapResponse)的mapResponse函数） 如果请求超时，允许actor重新发送消息（通过mapResponse回调函数里处理） 跟踪未完成的请求 保存上下文。发送者actor接收的请求有上下文信息（context.ask将生成一个临时actor，这个临时actor即可作为一个确定上下文的载体），如：请求ID reqId，而后端协议不支持这个参数时","title":"适用范围"},{"location":"/actor/actor-inside-ask.html#问题","text":"一个ask只能有一个响应（因为ask会创建一个临时actor，这个actor在收到响应后就会结束自己） 当请求超时时，接收actor（发回响应的那个）并不知道且仍可能将请求处理并完成，甚至若接收actor很忙的话会在请求超时发生以后再处理它 为超时情况找到一个好的（包装）值，特别是在ask函数调用后还会触发链式调用时（一个异步调用完成后进行另一个异步调用）。这时候希望来快速响应超时情况并回复请求者，但同时需要避免误报。","title":"问题"},{"location":"/actor/actor-inside-ask.html#完整代码","text":"/*\n * Copyright 2019 yangbajing.me\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cookbook.actor.pingpong\n\nimport java.util.concurrent.CountDownLatch\n\nimport akka.actor.typed.scaladsl.Behaviors\nimport akka.actor.typed.{ ActorRef, ActorSystem, Behavior, Terminated }\nimport akka.util.Timeout\n\nimport scala.concurrent.duration._\nimport scala.util.{ Failure, Success }\n\nobject Ping {\n  sealed trait Request\n  private final case class WrappedResponse(response: Pong.Response) extends Request\n  def apply(latch: CountDownLatch): Behavior[Request] = Behaviors.setup { context =>\n    implicit val timeout: Timeout = 2.seconds\n    val pong = context.spawn(Pong(), \"pong\")\n    context.watch(pong)\n    context.ask(\n      pong,\n      (replyTo: ActorRef[Pong.Response]) =>\n        Pong.Message(\"Hello Scala!\", 1, replyTo)) {\n      case Success(value)     => WrappedResponse(value)\n      case Failure(exception) => throw exception\n    }\n\n    Behaviors\n      .receiveMessage[Request] {\n        case WrappedResponse(Pong.Result(message, count)) =>\n          context.log.info(s\"Received pong response: $message, ${count}th.\")\n          context.ask[Pong.Request, Pong.Response](\n            pong,\n            Pong.Message(message, count + 1, _)) {\n            case Success(value)     => WrappedResponse(value)\n            case Failure(exception) => throw exception\n          }\n          Behaviors.same\n      }\n      .receiveSignal {\n        case (_, Terminated(`pong`)) =>\n          context.log.info(s\"Actor $pong be terminated.\")\n          latch.countDown()\n          Behaviors.stopped\n      }\n  }\n}\n\nobject Pong {\n  sealed trait Request\n  final case class Message(message: String, count: Int, replyTo: ActorRef[Response])\n      extends Request\n  sealed trait Response\n  final case class Result(message: String, count: Int) extends Response\n  def apply(): Behavior[Request] = Behaviors.receive {\n    case (context, Message(message, 100, _)) =>\n      context.log.info(s\"Receiving 100th Ping message: $message, it will stop.\")\n      Behaviors.stopped\n    case (_, Message(message, count, replyTo)) =>\n      replyTo ! Result(message, count)\n      Behaviors.same\n  }\n}\n\nobject PingPongMain {\n  def main(args: Array[String]): Unit = {\n    val latch = new CountDownLatch(1)\n    val system = ActorSystem(Ping(latch), \"ping-pong\")\n    latch.await()\n    system.terminate()\n  }\n}","title":"完整代码"},{"location":"/actor/actor-outside-ask.html","text":"","title":"Actor外使用ask（请求-响应模式）"},{"location":"/actor/actor-outside-ask.html#actor外使用ask-请求-响应模式-","text":"在与非Akka应用集成时，通常需要向actor发送一个请求并期待它有响应。这可以通过ask函数（或!）来实现。\nimport akka.actor.typed.scaladsl.AskPattern._\nimport scala.concurrent.duration._\n\nimplicit val system: ActorSystem[_] = system\nimplicit val timeout: Timeout = 3.seconds\n\nval result: Future[Hello.Response] = \n  cookieFabric.ask(ref => Hello.SayHello(\"Scala\", ref))\nNote import AskPattern._导入的ask函数本来需要有一个Scheduler的隐式参数，但object AskPattern还同时提供了一个schedulerFromActorSystem隐式函数从ActorSystem[_]获得Scheduler，这里建议直接使用implicit ActorSystem[_]（在使用Akka Streams时，也提供了从ActorSystem[_]获得Materializer的隐式转换函数，直接使用implicit ActorSystem[_]可以减少样版代码，使代码更清晰）。","title":"Actor外使用ask（请求-响应模式）"},{"location":"/actor/actor-outside-ask.html#适用范围","text":"从actor系统外部访问时，如Akka HTTP请求访问actor获取响应值","title":"适用范围"},{"location":"/actor/actor-outside-ask.html#问题","text":"在返回的Future回调内很可能意外的捕获了外部状态，因为这些回调将在与ask不同的线程上执行 一个ask只能有一个响应（ask将生成临时actor） 当请求超时时，接收actor并不知道且仍将继续处理请求直至完成，甚至可能会在超时发生后才开始处理它","title":"问题"},{"location":"/actor/create-actor-externally.html","text":"","title":"通过 ActorSystem 创建 actor"},{"location":"/actor/create-actor-externally.html#通过-actorsystem-创建-actor","text":"Akka Typed已不允许通过 ActorSystem 的实例来创建actor，推荐自定义的根actor来初始化整个actor树，并在构建 ActorSystem 作为守卫行为传入：\nval behavior: Behavior[T] = _ // 根actor，用于构建整个actor业务树\nval system = ActorSystem(behavior, \"typed\")\n但实际应用中，允许有充分的理由需要通过 ActorSystem 来创建actor，这有两种方式：\n使用 SpawnProtocol 为守卫actor提供自定义 Spawn 消息","title":"通过 ActorSystem 创建 actor"},{"location":"/actor/create-actor-externally.html#使用-spawnprotocol","text":"implicit val system = ActorSystem(SpawnProtocol(), \"spawn-protocol\")\nimplicit val timeout = Timeout(2.seconds)\nval pingF = system.ask[ActorRef[Ping.Command]](replyTo =>\n  SpawnProtocol.Spawn(Ping(), \"ping\", Props.empty, replyTo))\nval ping = Await.result(pingF, 2.seconds)\nping ! Ping.Start\nsystem.terminate()\n将Akka内置的SpawnProtocol作为ActorSystem的初始化行为，就可以通过SpawnProtocol.Spawn消息来创建actor。","title":"使用 SpawnProtocol"},{"location":"/actor/create-actor-externally.html#为守卫actor提供自定义-消息","text":"使用SpawnProtocol虽然可以在ActorSystem外部创建actor，但却没法使用我们自己定义的守卫actor了。参照 SpawnProtocol.Spawn 为自己的守卫actor提供Spawn消息，这样就可以在ActorSystem外部创建actor了。\nobject RootActor {\n  sealed trait Command\n  case class Spawn[T](\n      behavior: Behavior[T],\n      name: String,\n      props: Props,\n      replyTo: ActorRef[ActorRef[T]])\n      extends Command\n  // 在此添加其它业务消息\n\n  def apply(): Behavior[Command] = Behaviors.receive {\n    case (context, Spawn(behavior, name, props, replyTo)) =>\n      replyTo ! context.spawn(behavior, name, props)\n      Behaviors.same\n  }\n}\n通过此方式创建的所以actor都为是守卫actor的子actor。","title":"为守卫actor提供自定义 Spawn 消息"},{"location":"/actor/pipe-to-self.html","text":"","title":"将 Future 结果发送给自己"},{"location":"/actor/pipe-to-self.html#将-future-结果发送给自己","text":"当在actor内部执行异步操作（返回一个Future时）需要小心处理，因为actor与那个异步操作不在同一个线程。ActorContext[T]提供了pipeToSelf方法来将Future的结果安全的传给自己（actor）。\n在Future的onComplete回调函数里处理异步结果很方便、看起来也很诱人，但这样会引发很多潜在的危险，因为从外部线程访问actor内部状态不是线程安全的。例如：无法从类似回调中线程安全的访问示例的operationsInProgress计数器，所以，最好将响应映射到消息，并使用actor的消息接收机制来线程安全的执行进一步处理。\ncase Update(value, replyTo) =>\n  if (operationsInProgress == MaxOperationsInProgress) {\n    // ....\n    Behaviors.same\n  } else {\n    val futureResult = dataAccess.update(value)\n    context.pipeToSelf(futureResult) {\n      case Success(_) => WrappedUpdateResult(UpdateSuccess(value.id), replyTo)\n      case Failure(e) => WrappedUpdateResult(UpdateFailure(value.id, e.getMessage), replyTo)\n    }\n    next(dataAccess, operationsInProgress + 1)\n  }\ncase WrappedUpdateResult(result, replyTo) =>\n  replyTo ! result\n  next(dataAccess, operationsInProgress - 1)\nWarning context.pipeToSelf函数签名如下： def pipeToSelf[Value](future: Future[Value])(mapResult: Try[Value] => T): Unit\n 需要注意的是在mapResult函数中不能抛出异常，不让actor将被停止！","title":"将 Future 结果发送给自己"},{"location":"/actor/pipe-to-self.html#适用范围","text":"调用返回Future的外部服务时 当Future完成，actor需要继续处理时 保留原始请求的上下文，并在Future完成时使用它。如：replyTo: ActorRef[_]","title":"适用范围"},{"location":"/actor/pipe-to-self.html#问题","text":"为Future结果添加过多的包装消息","title":"问题"},{"location":"/actor/create-child-actor.html","text":"","title":"创建子 actor"},{"location":"/actor/create-child-actor.html#创建子-actor","text":"ActorContext[T]提供了spawn和spawnAnonymous来创建一个当前actor的直接子actor。spawn函数需要3个参数：\nbehavior：待创建为actor的行为 name：创建的actor的名字 props：创建属性参数，可以配置线程调度器等\ndef spawn[U](behavior: Behavior[U], name: String, props: Props = Props.empty): ActorRef[U]","title":"创建子 actor"},{"location":"/actor/timer.html","text":"","title":"TimerScheduler 发送消息"},{"location":"/actor/timer.html#timerscheduler-发送消息","text":"","title":"TimerScheduler 发送消息"},{"location":"/actor/timer.html#设置默认消息超时时间","text":"通过调用ActorContext[T]的setReceiveTimeout函数可以设置actor（当前actor实例）的默认消息超时时间，并在超时时间被触发时向actor发送指定消息。\ndef setReceiveTimeout(timeout: FiniteDuration, msg: T): Unit","title":"设置默认消息超时时间"},{"location":"/actor/timer.html#actor定时发送消息给自己","text":"Akka Typed提供了TimerScheduler[T]来启动计时器将指定消息发送给actor自己，支持单次、多次两种发送模式，而多次发送模式又支持两种计时策略：\n固定延迟（**fixed-delay**）：发送后续消息之章的延迟始终（不小于）为给定的值，使用startTimerWithFixedDelay函数 固定速率（**fixed-rate**）：一段时间内执行的频率满足给定的间隔，使用startTimerAtFixedRate函数\n如果不确定使用哪一个，建议选择startTimerWithFixedDelay。因为 固定速率 在长时间的垃圾收集暂停后可能会导致计划消息的突发，这在最坏的情况下可能会导致系统上出现预期外的负载。通常首选具有 固定延迟 的调度计划。\n当使用固定延迟时，如果由于某种原因，调度延迟超过指定的时间，则它不会补偿消息之间的延迟。发送后续消息之间的延迟总是（至少）给定的延迟。从长远来看，消息的频率通常会略低于指定延迟的倒数。\n固定延迟执行适用于需要“平滑度”的重复性活动。换句话说，它适用于短期内比长期内保持频率准确更为重要的活动。\n使用固定速率时，如果先前的消息延迟太长，它将补偿后续任务的延迟。在这种情况下，实际的发送间隔将不同于传递给 固定速率 方法的间隔。\n如果任务延迟超过间隔时间，则在前一个任务之后立即发送后续消息。这还会导致在长时间的垃圾收集暂停或JVM暂停时的其他原因之后，当进程再次唤醒时，将执行所有“错过”的任务。例如，间隔1秒的 固定速率 和暂停30秒的进程将导致连续快速发送30条消息以赶上之前错过的调度。从长远来看，执行频率正好是指定间隔的倒数。\n固定速率执行适用于对绝对时间敏感或执行固定数量执行的总时间很重要的重复活动，例如每秒计时一次并持续10秒的倒计时计时器。\nobject Timer {\n  sealed trait Command\n  case object ReceiveTimeout extends Command\n  case object SingleTrigger extends Command\n  case object TimerTrigger extends Command\n  case object CancelAllTimer extends Command\n\n  def apply(): Behavior[Command] =\n    Behaviors.setup(context =>\n      Behaviors.withTimers { timers =>\n        context.setReceiveTimeout(2.seconds, ReceiveTimeout)\n        timers.startSingleTimer(SingleTrigger, SingleTrigger, 2.seconds)\n        timers.startTimerAtFixedRate(TimerTrigger, TimerTrigger, 1.seconds)\n\n        Behaviors.receiveMessage {\n          case SingleTrigger =>\n            context.log.info(s\"Receive message: $SingleTrigger\")\n            Behaviors.same\n          case TimerTrigger =>\n            context.log.info(s\"Receive message: $TimerTrigger\")\n            Behaviors.same\n          case CancelAllTimer =>\n            context.log.info(s\"Receive message: $CancelAllTimer\")\n            timers.cancelAll()\n            Behaviors.same\n          case ReceiveTimeout =>\n            context.log.info(s\"Receive message: $ReceiveTimeout\")\n            Behaviors.same\n        }\n      })\n}\n测试程序：\nclass TimerTest extends ScalaTestWithActorTestKit with FunSuiteLike {\n  test(\"Timer\") {\n    val ref = spawn(Timer())\n    TimeUnit.SECONDS.sleep(5)\n    ref ! Timer.CancelAllTimer\n    TimeUnit.SECONDS.sleep(3)\n  }\n}\n上面程序的测试输出如下（已简化部分内容）：\n[akka://TimerTest/user/$a] - Receive message: TimerTrigger\n[akka://TimerTest/user/$a] - Receive message: TimerTrigger\n[akka://TimerTest/user/$a] - Receive message: SingleTrigger\n[akka://TimerTest/user/$a] - Receive message: TimerTrigger\n[akka://TimerTest/user/$a] - Receive message: TimerTrigger\n[akka://TimerTest/user/$a] - Receive message: CancelAllTimer\n[akka://TimerTest/user/$a] - Receive message: ReceiveTimeout","title":"actor定时发送消息给自己"},{"location":"/actor/change-behavior-and-state-machine.html","text":"","title":"行为切换与状态机"},{"location":"/actor/change-behavior-and-state-machine.html#行为切换与状态机","text":"Akka Typed使用Behavior替代了Actor，通过函数式的方式来构建消息处理行为，每次消息处理后都需要返回下一个（消息处理）行为。经典（Untyped）actor的become、unbecome和 FSM （状态机）都不再需要了，因为通过返回下一个行为时就已经可以实现以上功能。\n下面定义了一个简单的状态机actor，它有两个状态行为：idle和active，分别由passive和running两个事件消息来触发切换。\nobject FiniteStateMachine {\n  def apply(): Behavior[String] = Behaviors.setup { context =>\n    new FiniteStateMachine(context).idle()\n  }\n}\n\nclass FiniteStateMachine private (context: ActorContext[String]) {\n  private val pendingMessages = mutable.Queue.empty[String]\n\n  def idle(): Behavior[String] = Behaviors.receiveMessage {\n    case \"running\" =>\n      active()\n    case msg =>\n      context.log.info(s\"[idle] receive message: $msg\")\n      pendingMessages enqueue msg\n      Behaviors.same\n  }\n\n  def active(): Behavior[String] = Behaviors.receiveMessage {\n    case \"passive\" =>\n      idle()\n    case msg =>\n      context.log.info(s\"[active] receive message: $msg\")\n      processPendingMessages()\n      Behaviors.same\n  }\n\n  private def processPendingMessages(): Unit = {\n    while (pendingMessages.nonEmpty) {\n      val msg = pendingMessages.dequeue()\n      context.log.info(s\"Process pending message: $msg\")\n    }\n  }\n}\n这里使用了FiniteStateMachine类的方式来定义Behavior行为集，通过定义不同的类函数来实现在不同事件消息情况下的行为，这样还可通过类属性来保存actor的内部状态。初始时在Behavior.setup构造块里使用了idle这个行为函数，当收到running消息时通过返回active()函数实现了行为切换，就类似经典actor的become一样。\n当你的actor有多个行为函数，或代码逻辑（行）比较多时，通过这种 类 的方式来管理它们能使行代码更加清晰，这是一种良好的实践！\nNote 可以在FiniteStateMachine类构造块里作actor的初始化工作，也可以在Behaviors.setup里初始化后将数据通过构造参数传给FiniteStateMachine，就像context参数一样。 但需要注意的时，如何actor重启，pendingMessages将不会保存之前的状态（内容），因为FiniteStateMachine将被重新实例化。这可以通过某种持久化机制来解决，如： Akka Persistence ；或者在 PreRestart 信号处理函数里自行保存数据，再在类构造时读出。\n测试代码如下：\nval ref = spawn(FiniteStateMachine(), \"fsm\")\nref ! \"message 1\"\nref ! \"message 2\"\nref ! \"running\"\nref ! \"message 3\"\nref ! \"message 4\"\nref ! \"passive\"\nref ! \"message 5\"","title":"行为切换与状态机"},{"location":"/actor/stash.html","text":"","title":"StashBuffer 暂存待处理消息"},{"location":"/actor/stash.html#stashbuffer-暂存待处理消息","text":"在之前状态机的例子，在 idle 状态时通过pendingMessages属性来暂存待处理消息。这是一种很常见的业务状态，比如：等待数据库连接建立、等待后端服务启动完成等，都需要在这段时间内将请求的消息暂存下来，待服务可用时对其处理。Akka内置了对此的功能：StashBuffer[T]，它可以减少actor内你自己的定义可变状态属性，使代码更清晰、健壮……\nobject StashFSM {\n  def apply(): Behavior[String] = Behaviors.setup { context =>\n    Behaviors.withStash(1024)(stash => new StashFSM(stash, context).idle())\n  }\n}\nclass StashFSM private (stash: StashBuffer[String], context: ActorContext[String]) {\n  def idle(): Behavior[String] = Behaviors.receiveMessage {\n    case \"running\" =>\n      stash.unstashAll(active())\n    case msg =>\n      context.log.info(s\"[idle] receive message: $msg\")\n      stash.stash(msg)\n      Behaviors.same\n  }\n\n  def active(): Behavior[String] = Behaviors.receiveMessage {\n    case \"passive\" =>\n      idle()\n    case msg =>\n      context.log.info(s\"[active] receive message: $msg\")\n      Behaviors.same\n  }\n}\n当actor还未准备好服务时，通过stash.stash(msg)将消息暂存。待actor可以服务时，使用stash.unstashAll(active())来调用新的行为函数将所有暂存的消息按FIFO依次重放。\n通过使用 StashBuffer ，不需要在actor内部自行使用一个集合变量来暂存消息，也不需要单独定义一个函数来处理这些暂存消息。只需要定义你本当需要的业务代码，待actor可用（可服务）时重放所有暂存消息即可。\nclass StashFSMTest extends ScalaTestWithActorTestKit with FunSuiteLike {\n  test(\"StashFSM\") {\n    val ref = spawn(StashFSM(), \"fsm\")\n    ref ! \"message 1\"\n    ref ! \"message 2\"\n    ref ! \"running\"\n    ref ! \"message 3\"\n    ref ! \"message 4\"\n    ref ! \"passive\"\n    ref ! \"message 5\"\n  }\n}\n执行上面测试代码输出如下（已简化部分内容）：\n[akka://StashFSMTest/user/fsm] - [idle] receive message: message 1\n[akka://StashFSMTest/user/fsm] - [idle] receive message: message 2\n[akka://StashFSMTest/user/fsm] - [active] receive message: message 1\n[akka://StashFSMTest/user/fsm] - [active] receive message: message 2\n[akka://StashFSMTest/user/fsm] - [active] receive message: message 3\n[akka://StashFSMTest/user/fsm] - [active] receive message: message 4\n[akka://StashFSMTest/user/fsm] - [idle] receive message: message 5","title":"StashBuffer 暂存待处理消息"},{"location":"/actor/supervise.html","text":"","title":"处理 actor 异常"},{"location":"/actor/supervise.html#处理-actor-异常","text":"Akka实现了 Let it crash 模式，它假定失败是不可避免的。我们不应该花费过多的精力去设计一个永不失败的系统，而是假定失败在所难免，当失败发生时应快速的响应失败并以正确的状态重新启动。","title":"处理 actor 异常"},{"location":"/actor/supervise.html#监管策略","text":"通过Akka的监控机制，我们可以在actor发生异常时对其拦截并进行处理。默认的监管策略有：\nresume：忽略失败，并继续处理下一条消息（如果有） restart：重启actor stop：停止actor， 这是typed actor的默认行为，而untyped actor默认是重启","title":"监管策略"},{"location":"/actor/supervise.html#错误-validation-error-与失败-failure-","text":"但我们应该在发生任何异常时都应用Akka的监管策略吗？答案是否定的。对于错误（验证错误）与失败，两者之间有显著区别：\nValidation Error：验证错误通常是业务逻辑的一部分，不应该抛出异常！而应该建模的actor协议（消息）； Failure：对于 失败，应用 让它崩溃 模式是有用的。以一个干净地、可预测的全新状态恢复运行比通过大量的逻辑判断和try catch语句而污染了代码更有效。","title":"错误（Validation Error）与失败（Failure）"},{"location":"/actor/supervise.html#示例","text":"case class RestartException(message: String) extends RuntimeException(message)\ncase class StopException(message: String) extends RuntimeException(message)\n\nsealed trait Command\nfinal case object Message extends Command\nfinal case object Restart extends Command\nfinal case object Stop extends Command\n\ndef apply(): Behavior[Command] = Behaviors.setup { context =>\n  println(s\"${context.self} started.\")\n  Behaviors\n    .receiveMessage[Command] {\n      case Message =>\n        println(s\"${context.self} Received Message.\")\n        Behaviors.same\n      case Restart =>\n        throw RestartException(\"可重启\")\n      case Stop =>\n        throw StopException(\"退出\")\n    }\n    .receiveSignal {\n      case (context, PreRestart) =>\n        println(s\"${context.self} Received signal $PreRestart\")\n        Behaviors.same\n      case (context, PostStop) =>\n        println(s\"${context.self} Received signal $PostStop\")\n        Behaviors.same\n    }\n}\n通过Behaviors.supervise来包裹 behavior 来实现监管策略。多个监管策略可以使用Behaviors.supervise嵌套来实现。\nBehaviors\n  .supervise(Behaviors.supervise(FaultTolerance()).onFailure[RestartException](SupervisorStrategy.restart))\n  .onFailure[StopException](SupervisorStrategy.stop)\n运行示例输出内容如下（隐藏了部分日志输出）：\nActor[akka://fault-tolerance/user#0] started.\nActor[akka://fault-tolerance/user#0] Received Message.\nActor[akka://fault-tolerance/user#0] Received signal PreRestart\n[2019-11-19 19:51:48,105] [ERROR] [akka.actor.typed.Behavior$] [fault-tolerance-akka.actor.default-dispatcher-3] [akka://fault-tolerance/user] - Supervisor RestartSupervisor saw failure: 可重启\n....\nActor[akka://fault-tolerance/user#0] started.\n[2019-11-19 19:51:49,070] [ERROR] [akka.actor.LocalActorRefProvider(akka://fault-tolerance)] [fault-tolerance-akka.actor.default-dispatcher-3] [akka.actor.LocalActorRefProvider(akka://fault-tolerance)] - guardian failed, shutting down system\n....\n[2019-11-19 19:51:49,071] [ERROR] [akka.actor.OneForOneStrategy] [fault-tolerance-akka.actor.default-dispatcher-3] [akka://fault-tolerance/user] - 退出\n....\nActor[akka://fault-tolerance/user#0] Received signal PostStop","title":"示例"},{"location":"/actor/supervise.html#监管树","text":"Akka Typed的监管策略里没有了经典（Untyped）actor的 Escalate 策略。就是说Akka Typed默认是不支持异常冒泡的，需要**watch**子actor，并监听ChildFailed信号并再手动重新抛出异常，或者不处理子actor的终止信息而自动抛出DeathPactException异常。关于这方面的内容请参阅： 怎样向上冒泡异常。","title":"监管树"},{"location":"/actor/watch-actor.html","text":"","title":"监视 actor 的停止状态"},{"location":"/actor/watch-actor.html#监视-actor-的停止状态","text":"一个actor可以通过context.watch函数监听其它actor的终止情况，在Terminated或ChildFailed信号发出时对其进行捕获并处理。\nNote Akka Typed默认不会 watch 创建的子actor，若需要监听子actor的终止信号需要手动 watch。\nTerminated信号通过ref属性告知监听者是哪个actor已终止。ChildFailed信号作为Termianted的子类，它除了ref指出是哪个actor已终止外，还通过cause属性告知子actor终止时被抛出的异常。\n示例代码请见： 怎样向上冒泡异常#示例代码。","title":"监视 actor 的停止状态"},{"location":"/actor/escalate-exception.html","text":"","title":"怎样向上冒泡异常"},{"location":"/actor/escalate-exception.html#怎样向上冒泡异常","text":"对于经典（Untyped）actor的 Escalate 监管策略，Akka Typed并未提供直接的支持，但有两种方式可以实现类似效果。\n不处理子actor的终止异常（Terminated或ChildFailed信号），这样actor将自动抛出akka.actor.typed.DeathPactException异常。但这样会使导致失败的原始异常被吞掉，因为这个异常将告知直接父actor（这某种程度上说是一件好事，这样就不会泄露实现细节）。 监听子actor的终止异常，再重新抛出，这里父actor可以选择将导致子actor失败的原始直接抛出或做个封装。","title":"怎样向上冒泡异常"},{"location":"/actor/escalate-exception.html#示例代码","text":"final case class EscalateException(message: String)\n    extends RuntimeException(message)\nfinal case class ActorException(ref: ActorRef[Nothing], cause: Throwable)\n    extends RuntimeException(cause)\n\nobject Child {\n  sealed trait Command\n  case object ThrowNormalException extends Command\n  case object ThrowEscalateException extends Command\n  def apply(): Behavior[Command] = Behaviors.setup { context =>\n    context.log.info(\"started.\")\n    Behaviors\n      .receiveMessage[Command] {\n        case ThrowEscalateException =>\n          throw EscalateException(\"This is escalate exception.\")\n        case ThrowNormalException =>\n          throw new RuntimeException(\"This is normal exception.\")\n      }\n      .receiveSignal {\n        case (_, PreRestart) =>\n          context.log.info(\"Pre restart.\")\n          Behaviors.same\n        case (_, PostStop) =>\n          context.log.info(\"stopped.\")\n          Behaviors.same\n      }\n  }\n}\n\nobject Parent {\n  sealed trait Command\n  def apply(): Behavior[Command] = Behaviors.setup { context =>\n    import context.executionContext\n    val child1 = context.spawn(Child(), \"child1\")\n    context.watch(child1)\n    val child2 = context.spawn(Child(), \"child2\")\n    context.watch(child2)\n    child2 ! Child.ThrowNormalException\n    context.system.scheduler\n      .scheduleOnce(1.second, () => child1 ! Child.ThrowEscalateException)\n    Behaviors.receiveSignal {\n      case (_, ChildFailed(ref, e: EscalateException)) =>\n        throw ActorException(ref, e)\n      case (_, ChildFailed(ref, e)) =>\n        context.log.warn(\n          s\"Received child actor ${ref.path} terminated signal, original exception is $e\")\n        Behaviors.same\n    }\n  }\n}\n\nobject Root {\n  sealed trait Command\n  def apply(): Behavior[Command] = Behaviors.setup { context =>\n    val parent = context.spawn(Parent(), \"parent\")\n    context.watch(parent)\n    Behaviors.receiveSignal {\n      case (_, ChildFailed(ref, e)) =>\n        context.log.info(\n          s\"Received child actor ${ref.path} failed signal, original exception is $e\")\n        Behaviors.same\n      case (_, Terminated(ref)) =>\n        context.log.info(s\"Received actor ${ref.path} terminated signal.\")\n        Behaviors.same\n    }\n  }\n}\n\nobject WatchActorMain {\n  def main(args: Array[String]): Unit = {\n    val system = ActorSystem(Root(), \"watch\")\n    TimeUnit.SECONDS.sleep(2)\n    system.terminate()\n  }\n}\n运行代码可以看到如下输出（输出内容已作简化）：\n[20:25:03,475] [INFO] [cookbook.actor.fault.Child$] \n    [akka://watch/user/parent/child2] - started.\n[20:25:03,475] [INFO] [cookbook.actor.fault.Child$]\n    [akka://watch/user/parent/child1] - started.\n....\n[20:25:03,509] [INFO] [cookbook.actor.fault.Child$]\n    [akka://watch/user/parent/child2] - stopped.\n[20:25:03,513] [WARN] [akka.actor.SupervisorStrategy]\n    [akka://watch/user/parent] - Received child actor \n    akka://watch/user/parent/child2 failed signal, original \n    exception is java.lang.RuntimeException: This is normal exception.\n....\n[20:25:04,490] [INFO] [cookbook.actor.fault.Child$]\n    [akka://watch/user/parent/child1] - stopped.\n....\n[20:25:04,491] [INFO] [akka.actor.SupervisorStrategy]\n    [akka://watch/user] - Received child actor \n    akka://watch/user/parent failed signal, original \n    exception is cookbook.actor.fault.ActorException: \n    cookbook.actor.fault.EscalateException: This is escalate exception.","title":"示例代码"},{"location":"/actor/stop.html","text":"","title":"怎样优雅的停止actor"},{"location":"/actor/stop.html#怎样优雅的停止actor","text":"","title":"怎样优雅的停止actor"},{"location":"/actor/stop.html#返回-behaviors-stopped","text":"每处理一个消息，actor都将返回一个行为，可以通过返回 Behaviors.stopped 行为来告诉Actor系统此actor应被自动停止。\ncase (context, Stop) =>\n  context.log.info(s\"Receive message: $Stop, will stopped.\")\n  Behaviors.stopped\nBehaviors.stopped被执行时将触发 PostStop 信号。","title":"返回 Behaviors.stopped"},{"location":"/actor/stop.html#graceful-stop","text":"通常，PostStop信号被作为非正常停止看待，若想在正常停止（Graceful Stop）时触发一些清理操作，可将清理函数（cleanup）传给Behaviors.stopped的重载版本。\ncase (context, GracefulStop) =>\n  context.log.info(s\"Receive message: $GracefulStop, will stopped.\")\n  Behaviors.stopped(() => cleanup(context.log))\n当 PostStop 信号被处理后，cleanup清理函数将紧接着执行。\ndef cleanup(log: Logger): Unit = {\n  log.info(\"Perform cleanup action.\")\n}\nNote Akka Typed不再提供PoisonPill消息来停止actor，推荐使用自定义消息并反回Behaviors.stopped行为来停止actor。","title":"Graceful Stop"},{"location":"/actor/lifecycle.html","text":"","title":"Actor 生命周期"},{"location":"/actor/lifecycle.html#actor-生命周期","text":"Akka Typed以函数式的方式构建，使用Behavior[T]函数的方式替代了经典（Untyped）Actor类的方式来创建actor。相应的，已没有了preStart、postStop、preRestart、postRestart等生命周期回调函数，采用Behaviors.setup构造块和信号的方式来实现一个actor生命周期管理功能。\nAkka Typed actor生命周期已简化为4个部分：\n开始：通常将Behaviors.receive消息处理逻辑包装在Behaviors.setup代码块里，在setup代码块里进行业务初始工作，如：打开外部资源等 消息处理：处理消息并返回下一个行为 重启前：若设置了SupervisorStrategy.restart监管策略，则在actor被重启前将收到PreRestart信号，可在此选择对资源做同步或清理工作 停止后：在actor被停止后，将收到PostStop信号，可在此做数据持久化和资源清理工作\nNote 建议PreRestart和PostStop可执行相同的数据持久化和资源清理工作，这样在重新执行Behaviors.setup的构造逻辑时能和第一次创建actor时保持一致。这也更符合 Let it crash 精神！\nobject Lifecycle {\n  def apply(): Behavior[String] = Behaviors.setup { context =>\n    context.log.info(\"actor started.\")\n    Behaviors\n      .receiveMessage[String] {\n        case \"restart\" =>\n          context.log.info(\"Beginning restart.\")\n          throw new RuntimeException(\"Beginning restart.\")\n        case message =>\n          context.log.info(s\"Received message is $message\")\n          Behaviors.same\n      }\n      .receiveSignal {\n        case (_, PreRestart) =>\n          context.log.info(\"actor pre restart.\")\n          Behaviors.same\n        case (_, PostStop) =>\n          context.log.info(\"actor post stop.\")\n          Behaviors.same\n      }\n  }\n}\n下面是Lifecycle行为的测试代码：\nclass LifecycleTest extends ScalaTestWithActorTestKit with WordSpecLike {\n  \"Lifecycle\" should {\n    \"lifecycle\" in {\n      val ref = spawn(\n        Behaviors.supervise(Lifecycle()).onFailure(SupervisorStrategy.restart))\n      ref ! \"hello\"\n      TimeUnit.SECONDS.sleep(1)\n      ref ! \"restart\"\n      TimeUnit.SECONDS.sleep(1)\n    }\n  }\n}\n运行测试输出如下（简化了部分输出内容）：\n[19:43:10,971] [akka://LifecycleTest/user/$a] - actor started.\n[19:43:10,972] [akka://LifecycleTest/user/$a] - Received message is hello\n[19:43:11,970] [akka://LifecycleTest/user/$a] - Beginning restart.\n[19:43:11,973] [akka://LifecycleTest/user/$a] - actor pre restart.\n....\n[19:43:11,977] [akka://LifecycleTest/user/$a] - actor started.\n[19:43:13,009] [akka://LifecycleTest/user/$a] - actor post stop.","title":"Actor 生命周期"},{"location":"/streams/index.html","text":"","title":"Akka 流（Streams）"},{"location":"/streams/index.html#akka-流-streams-","text":"介绍 第一个示例 Source、Flow、Sink Graph Shape RunnableGraph 深入 Source Source SourceShape Source 怎么生产数据？ FileSource 实例讲解 createLogicAndMaterializedValue GraphStageLogic 详解 小结 物化与物化值 Materializer（物化器） Materialized value（物化值） Keep 深入 Flow 深入 Sink 创建 Source 的常用函数 fromPublisher asSubscriber fromIterator cycle fromGraph apply queue 执行转换的 Flow 常用函数 汇聚数据的 Sink 常用函数 Streams 分组 grouped groupedWithin 基于时间的处理 访问文件 FileIO.toPath 写数据到文件 FileIO.fromPath 从文件读数据 访问FTP/sFTP 自定义图（Graph）","title":"Akka 流（Streams）"},{"location":"/streams/introduction.html","text":"","title":"介绍"},{"location":"/streams/introduction.html#介绍","text":"Akka Streams是 Reactive Streams 的一种实现，提供了对反应式编程（见：《反应式宣言》）的支持。","title":"介绍"},{"location":"/streams/introduction.html#第一个示例","text":"Source\n  .fromIterator(() => Iterator.from(0))\n  .map(n => n.toString)\n  .take(10)\n  .runForeach(println)\n运行上面的示例，将在终端从0开始按递增数字每个数字并将其转换成字符串打印10行，每个字符串一行。\n明细版\nimport akka.Done\nimport akka.actor.typed.ActorSystem\nimport akka.actor.typed.scaladsl.Behaviors\nimport akka.stream.Materializer\nimport akka.stream.scaladsl.{ Flow, Keep, Sink, Source }\n\nimport scala.concurrent.duration._\nimport scala.concurrent.{ Await, Future }\n\nobject Startup {\n  def main(args: Array[String]): Unit = {\n    val system = ActorSystem(Behaviors.ignore, \"streams\")\n    implicit val mat = Materializer(system)\n\n    val source = Source.fromIterator(() => Iterator.from(0))\n    val flow = Flow[Int].map(n => n.toString)\n    val flowTake = Flow[String].take(10)\n    val sink = Sink.foreach[String](str => println(str))\n    val graph = source.via(flow).via(flowTake).toMat(sink)(Keep.right)\n\n    val future: Future[Done] = graph.run()\n    val result = Await.result(future, 10.seconds)\n    println(s\"Final result is $result\")\n  }\n}\n这个版本拆分了各个步骤：\nsource: Source[Int, NotUsed]：源，生产数据元素待下游消费 flow: Flow[Int, String, NotUsed]：流，将数字转换成字符串 flowTake: Flow[String, String, NotUsed]：流，限制只取头10个元素 sink: Sink[String, Future[Done]]：汇，生产的数据最终流到这里并被消费 graph: RunnableGraph[Future[Done]]：将source、flow、flowTake、sink各部分连接起来就形成了一个可运行的执行蓝图\nAkka Streams是lazy的，每次运行都全新的，中间状态将不会被保留。当调用graph的.run函数运行时需要上下文内有一个隐式参数：Materializer，它将负责实际执行这个蓝图（创建actor来执行）。\nNote 可以通过ActorSystem隐式获取全局默认的Materializer，这在通常情况下是很好的选择，除非你有特别的理由需要自定义Materializer。 implicit val system: ActorSystem = _\n akka.actor.typed.ActorSystem[T]和akka.actor.ActorSystem在Materializer的伴身对象里都有隐式函数来获取Materializer。","title":"第一个示例"},{"location":"/streams/introduction.html#source-flow-sink","text":"Akka Streams 将流处理逻辑抽像了 Source、**Flow**和**Sink** 三部分概念。\nSource: [OUT, Mat]：源，上游。生产数据，默认需要由下游调用pull请求触发。 Flow: [IN, OUT, Mat]：流程、转换，数据转换步骤。可对流过的数据元素作各种转换操作，如：格式化、类型转换，过滤……甚至可以自定义一个流处理图来实现更复杂的功能。连接Flow转入端的称为Flow的上游，连接转出端的称为Flow的上游。当Source通过viaMat函数把Flow连接起来，返回值是一个新的Source，Flow的输出端既是这个新Source的输出端。 Sink: [IN, Mat]：汇，下游。汇集上游发送的数据。","title":"Source、Flow、Sink"},{"location":"/streams/introduction.html#graph","text":"Akka Streams 使用 Graph （图）来抽像流处理的逻辑。\ntrait Graph[+S <: Shape, +M] {\n\n  type Shape = S @uncheckedVariance\n\n  def shape: S\n\n  private[stream] def traversalBuilder: TraversalBuilder\n\n  def withAttributes(attr: Attributes): Graph[S, M]\n\n  // ....\n}","title":"Graph"},{"location":"/streams/introduction.html#shape","text":"一个图可以有形状，形状描述图的入口（inlets、输入端口）和出口（outlets、输出端口）。\nabstract class Shape {\n  def inlets: immutable.Seq[Inlet[_]]\n  def outlets: immutable.Seq[Outlet[_]]\n  // ....\n}\n具有未连接的端口的图是一个部分图，图可以嵌套、组合。当图里所有端口都有连接，我们称这个图已闭合（ClosedShape），这样的图就可以成为一个可运行的图（RunnableGraph）。","title":"Shape"},{"location":"/streams/introduction.html#runnablegraph","text":"RunnableGraph是可运行的图，调用它的run函数将实际执行\nfinal case class RunnableGraph[+Mat](override val traversalBuilder: TraversalBuilder) extends Graph[ClosedShape, Mat] {}\n可运行图必须是逻辑上已闭合的图，它不能有未连接的端口。","title":"RunnableGraph"},{"location":"/streams/depth-source.html","text":"","title":"深入 Source"},{"location":"/streams/depth-source.html#深入-source","text":"","title":"深入 Source"},{"location":"/streams/depth-source.html#source","text":"Source是一组流（Streams）处理步骤，有一个打开的输出端口。Source可以包含任意数量已连接的内部源（Source）和转换操作（Flow）。Source可以通过asPublisher函数转换为 Reactive Streams 协议等价的Publisher。\nfinal class Source[+Out, +Mat](\n    override val traversalBuilder: LinearTraversalBuilder,\n    override val shape: SourceShape[Out])\n    extends FlowOpsMat[Out, Mat]\n    with Graph[SourceShape[Out], Mat]\nSource的类签名有两个类型参数，它们都是协变的。\nOut：输出元素类型 Mat：物化值类型，物化值可用于记录Source的内部状态或操作记录等。比如：FileIO.fromPath这个Source的物化值记录了从文件里实际读取到的字符数。\nSource通过类构造器实现了Graph接口的traversalBuilder和shape两个参数，其中shape限制了必须为一个SourceShape[Out]类型。\nSource还实现了FlowOpsMat特质，使得Source具有了一系列的via、to（及它们的变体）函数和丰富和流程转换函数（Flow操作符）。\nvia：用于连接Flow，它将一个流处理过程与当前Source连接，并返回另一个Source，其中Flow的输出端口将作为新Source的输出端口 viaMat：相对via多了第二个curry参数，combine指定保留哪边的物化值。via实际上相当于：viaMat(....)(Keep.left) def viaMat[T, Mat2, Mat3](flow: Graph[FlowShape[Out, T], Mat2])(\n      combine: (Mat, Mat2) => Mat3): Source[T, Mat3]\n to：用于连接Sink，Sink将从上游发送的元素都聚合到一起并处理。当一个Source连接了Sink后，即形成了一个已闭合的可运行图（ RunnableGraph ），我们可以调用RunnableGraph的run函数来实际运行它。 toMat：相对to多了第二个curry参数，combine指定保留哪边的物化值。to实际上相当于：toMat(....)(Keep.left) toMat[Mat2, Mat3](sink: Graph[SinkShape[Out], Mat2])(\n      combine: (Mat, Mat2) => Mat3): RunnableGraph[Mat3]\n有关combine函数的更多内容请见： 物化与物化值#Keep\n通常我们都不会直接构造Source，而是通过Source的伴身对象提供了各类工具函数来创建。有关Source伴身对象的常用工具函数请参阅： 创建 Source 的常用函数。","title":"Source"},{"location":"/streams/depth-source.html#sourceshape","text":"final case class SourceShape[+T](out: Outlet[T @uncheckedVariance]) extends Shape {\n  override val inlets: immutable.Seq[Inlet[_]] = EmptyImmutableSeq\n  override val outlets: immutable.Seq[Outlet[_]] = out :: Nil\n\n  override def deepCopy(): SourceShape[T] = SourceShape(out.carbonCopy())\n}\nSourceShape使用了final做修饰，这就确定了Source的形状（shape）只能为SourceShape，而且限制为没有输入端口，只有一个输出端口的形状；唯一可定义的地方就是它的输出端口发送出数据的类型。","title":"SourceShape"},{"location":"/streams/depth-source.html#source-怎么生产数据-","text":"Source是怎么生产数据并发送到下游的呢？是在GraphStageLogic里调用push函数将数据推送到下游的。GraphStageLogic用于定义图处理实际逻辑，它需要通过GraphStageWithMaterializedValue抽像类提供的方法创建，而这人抽像类继承了Graph特质。\n通常我们不会直接使用Graph来构建自己的图结构，而是会使用GraphStageWithMaterializedValue（或它的某个子类，接下来统称它们为 GraphStage ）。 GraphStage 是一个可重复使用的流处理操作图（a reusable graph stream processing operator），常用的 GraphStage 有两个：\nGraphStageWithMaterializedValue：有物化值的操作图，这样的图构造的 Source 签名类似：Source[Out, Mat]。 GraphStage：不需要物化值的操作图，这样的图构造出的 Source 签名类似：Source[Out, NotUsed]；\nabstract class GraphStageWithMaterializedValue[+S <: Shape, +M]\n    extends Graph[S, M] {\n  @throws(classOf[Exception])\n  def createLogicAndMaterializedValue(inheritedAttributes: Attributes): (GraphStageLogic, M)\n\n  protected def initialAttributes: Attributes = Attributes.none\n}\n\nabstract class GraphStage[S <: Shape] \n    extends GraphStageWithMaterializedValue[S, NotUsed] {\n  final override def createLogicAndMaterializedValue(inheritedAttributes: Attributes): (GraphStageLogic, NotUsed) =\n    (createLogic(inheritedAttributes), NotUsed)\n\n  @throws(classOf[Exception])\n  def createLogic(inheritedAttributes: Attributes): GraphStageLogic\n}\nGraphStageWithMaterializedValue有一个抽像方法待实现，它返回图处理逻辑和物化值的元组，类型为：(GraphStageLogic, M)。GraphStage继承了GraphStageWithMaterializedValue，它实现了createLogicAndMaterializedValue方法并将物化值固定为NotUsed，同时提供createLogic供实现类创建图处理逻辑。\n回到GraphStageLogic的push函数，通过它将数据元素发送到指定的输出端口。通常我们可以在onPull事件响应函数里调用它，onPull函数将由下游通过pull函数触发。\nfinal protected def push[T](out: Outlet[T], elem: T): Unit\n向指定的输出端口发射数据元素，在pull事件到达之前调用此方法两次将失败，在任何时间只能有一个未完成的推送请求。方法isAvailable可用于检查输出端口是否已准备好被推送。","title":"Source 怎么生产数据？"},{"location":"/streams/depth-source.html#filesource-实例讲解","text":"一般不会通过new的方式直接创建一个Source出来，而是通过调用Source.fromGraph从一个预定义好的图创建，如：\ndef fromPath(\n    f: Path, \n    chunkSize: Int, \n    startPosition: Long): Source[ByteString, Future[IOResult]] =\n  Source\n    .fromGraph(new FileSource(f, chunkSize, startPosition))\n    .withAttributes(DefaultAttributes.fileSource)\n这里通过Akka Streams自带的FileSource讲述Source图的定义过程。FileSource通过自定文件创建一个异步的文件读取源（Source）。\nfinal case class IOResult(count: Long)\n\nprivate[akka] final class FileSource(\n      path: Path,\n      chunkSize: Int,\n      startPosition: Long)\n    extends GraphStageWithMaterializedValue[SourceShape[ByteString], Future[IOResult]] {\n  require(chunkSize > 0, \"chunkSize must be greater than 0\")\n  val out = Outlet[ByteString](\"FileSource.out\")\n\n  override val shape = SourceShape(out)\n  // ....\n}\nFileSource要保存从文件实际读取字符数，所有它通过继承GraphStageWithMaterializedValue将计数通过物化值向下游传递。同时这个计数值不能阻塞整个流处理过程，所以物化值类型为：Future[IOResult]。\nSource[Out, Mat]的类型签名只有输出类型，也许你会奇怪它实际要处理的数据源来自哪里？看到这里FileSource(path: Path, ....)的构造函数签名即可明白，它实际要处理的数据源就是path指定的文件路径，通常在实现自己的Source时，我们都要继承Graph的某个抽像子类，再在主构造函数里传入它要处理的实际数据源。\nNote IOResult的count变量是文件读取的位置（字节），实际读取文件字节数需要通过count - startPosition来获得，因为有可能并不是从文件头开始读取。","title":"FileSource 实例讲解"},{"location":"/streams/depth-source.html#createlogicandmaterializedvalue","text":"override def createLogicAndMaterializedValue(inheritedAttributes: Attributes): (GraphStageLogic, Future[IOResult]) = {\n    val ioResultPromise = Promise[IOResult]()\n    val logic: GraphStageLogic = new GraphStageLogic(shape) with OutHandler {\n      val buffer = ByteBuffer.allocate(chunkSize)\n      val maxReadAhead = inheritedAttributes.get[InputBuffer](InputBuffer(16, 16)).max\n      var channel: FileChannel = _\n      var position = startPosition\n      var eofEncountered = false\n      var availableChunks: Vector[ByteString] = Vector.empty[ByteString]\n\n      setHandler(out, this)\n      // ....\n    }\n    (logic, ioResultPromise.future)\n  }\n变量logic和ioResultPromise，将作为createLogicAndMaterializedValue函数的返回值。login匿名实现了从path文件读取数据并发送到下游的功能逻辑，在图成功或失败完成时将position（读取到文件的位置偏移处（字节））","title":"createLogicAndMaterializedValue"},{"location":"/streams/depth-source.html#graphstagelogic-详解","text":"图属性变量\nval buffer = ByteBuffer.allocate(chunkSize)\nval maxReadAhead = inheritedAttributes.get[InputBuffer](InputBuffer(16, 16)).max\nvar channel: FileChannel = _\nvar position = startPosition\nvar eofEncountered = false\nvar availableChunks: Vector[ByteString] = Vector.empty[ByteString]\nbuffer：每次从文件里读取数据块缓存，读取的数据块将追加到availableChunks maxReadAhead：availableChunks长度，限制最多可向前读取的最大次数 channel：低层FileChannel position：当前文件读取打针位置 eofEncoutered：是否读到文件尾 availableChunks：缓存的未处理数据块\n图的初始化\noverride def preStart(): Unit = {\n    try {\n      // this is a bit weird but required to keep existing semantics\n      if (!Files.exists(path)) throw new NoSuchFileException(path.toString)\n\n      require(!Files.isDirectory(path), s\"Path '$path' is a directory\")\n      require(Files.isReadable(path), s\"Missing read permission for '$path'\")\n\n      channel = FileChannel.open(path, StandardOpenOption.READ)\n      channel.position(position)\n    } catch {\n      case ex: Exception =>\n        ioResultPromise.trySuccess(IOResult(position, Failure(ex)))\n        throw ex\n    }\n  }\n校验path指定的文件是否存在、是否可读，并以指定的偏移量位置打开 FileChannel。\nonPull\noverride def onPull(): Unit = {\n    if (availableChunks.size < maxReadAhead && !eofEncountered)\n      availableChunks = readAhead(maxReadAhead, availableChunks)\n    //if already read something and try\n    if (availableChunks.nonEmpty) {\n      emitMultiple(out, availableChunks.iterator, () => if (eofEncountered) success() else setHandler(out, handler))\n      availableChunks = Vector.empty[ByteString]\n    } else if (eofEncountered) success()\n  }\n当收到下游拉取数据请求时，通过readAhead函数从channel中读取尽量多的数据块 当availableChunks不为空，通过emitMultiple函数高效的将多个可用数据块 push 到下游。\nfinal protected def emitMultiple[T](out: Outlet[T], elems: Iterator[T], andThen: () => Unit): Unit\nemitMultiple函数可以简化需要发射多个元素的工作，它将在多个元素发射完成后恢复原有的处理程序（OutHandler），这样就不需要自己手动管理多个元素的发射状态。\nreadAhead，读取数据\nprivate def success(): Unit = {\n    completeStage()\n    ioResultPromise.trySuccess(IOResult(position, Success(Done)))\n  }\n  /** BLOCKING I/O READ */\n  @tailrec def readAhead(maxChunks: Int, chunks: Vector[ByteString]): Vector[ByteString] =\n    if (chunks.size < maxChunks && !eofEncountered) {\n      val readBytes = try channel.read(buffer, position)\n      catch {\n        case NonFatal(ex) =>\n          failStage(ex)\n          ioResultPromise.trySuccess(IOResult(position, Failure(ex)))\n          throw ex\n      }\n\n      if (readBytes > 0) {\n        buffer.flip()\n        position += readBytes\n        val newChunks = chunks :+ ByteString.fromByteBuffer(buffer)\n        buffer.clear()\n\n        if (readBytes < chunkSize) {\n          eofEncountered = true\n          newChunks\n        } else readAhead(maxChunks, newChunks)\n      } else {\n        eofEncountered = true\n        chunks\n      }\n    } else chunks\nreadAhead是一个尾递归函数，编译器在编译时会将其优化成循环调用，这样可避免栈溢出和性能问题。readAhead首先判断chunks是否未满或还有文件可读，若是则进行文件数据读取，否直接返回chunks。当channel.read返回的实际读出字节数readBytes大于0且不小于chunkSize，代表文件还有数据可继续读取，这时递归readAhead函数；否则设置 eofEncoutered为true并返回newChunks。\nonDownstreamFinish\noverride def onDownstreamFinish(cause: Throwable): Unit = {\n    cause match {\n      case _: SubscriptionWithCancelException.NonFailureCancellation =>\n        success()\n      case ex =>\n        ioResultPromise.tryFailure(\n          new IOOperationIncompleteException(\"Downstream failed before reaching file end\", position, ex))\n        completeStage()\n    }\n  }\n当下游取消（cancel）时，会触发onDownstreamFinish函数，并通过cause参数告知下游取消时的异常，在此也完成当前Source。\npostStop\noverride def postStop(): Unit = {\n    ioResultPromise.trySuccess(IOResult(position, Success(Done)))\n    if ((channel ne null) && channel.isOpen) channel.close()\n  }\n在图停止后做清理工作，关闭打开的文件。","title":"GraphStageLogic 详解"},{"location":"/streams/depth-source.html#小结","text":"完整FileSource源码见：https://github.com/akka/akka/blob/master/akka-stream/src/main/scala/akka/stream/impl/io/IOSources.scala。","title":"小结"},{"location":"/streams/materialize.html","text":"","title":"物化与物化值"},{"location":"/streams/materialize.html#物化与物化值","text":"","title":"物化与物化值"},{"location":"/streams/materialize.html#materializer-物化器-","text":"物化器负责将流蓝图（RunnableGraph）转换成可运行的流（通过在内部创建actor来异步执行）。通常来说首选系统范围的物化器，不需要我们手动创建它。\n有两种方式来选择系统范围的物化器：\n通过隐式转换函数从ActorSystem获取，akka.actor.typed.ActorSystem和akka.actor.ActorSystem都支持。 implicit val system: ActorSystem[Nothing]\n 通过SystemMaterializerAkka扩展。 // untyped ActorSystem\nSystemMaterializer(system).materializer\n// typed ActorSystem\nimport akka.actor.typed.scaladsl.adapter._\nSystemMaterializer(system.toClassic).materializer","title":"Materializer（物化器）"},{"location":"/streams/materialize.html#materialized-value-物化值-","text":"当一个可运行图（RunnableGraph）被执行（run），它将返回一个值（结果）。而这个值被称为 Materialized Value （物化值）。物化值可以是Sink处理后的结果，也可以是Source内部记录的统计数据……。\nSource[OUT, Mat]\nFlow[IN, OUT, Mat]\nSink[IN, Mat]\n这里的OUT、IN是在流处理过程中流通的每个数据元素的类型，整个流处结束后最终返回的结果是从Source、Flow、Sink各部分的Mat参数类型里选择的。Source、Flow、Sink每个的最后一个类型参数Mat就是物化值。带Mat后缀的操作函数提供了combine函数参数来选择要保留的物化值，如：viaMat、toMat。\nSource的物化值一般用于记录数据源的内部状态；Flow的物化值通常都会将上游的物化值向下传递（Keep.left），也可以调用其它Keep函数里自定义向下传递的物化值；Sink的物化值通常用于汇总上游发送的数据。\ndef viaMat[T, Mat2, Mat3](flow: Graph[FlowShape[Out, T], Mat2])(\n      combine: (Mat, Mat2) => Mat3): Source[T, Mat3]\ndef toMat[Mat2, Mat3](sink: Graph[SinkShape[Out], Mat2])(\n      combine: (Mat, Mat2) => Mat3): RunnableGraph[Mat3]","title":"Materialized value（物化值）"},{"location":"/streams/materialize.html#keep","text":"object Keep定义了4个便捷函数来选择保留图执行过程的哪个物化值，通常我们通过选择其中一个来作为调用viaMat或toMat函数时传递给combine参数的值。\nobject Keep {\n  private val _left = (l: Any, _: Any) => l\n  private val _right = (_: Any, r: Any) => r\n  private val _both = (l: Any, r: Any) => (l, r)\n  private val _none = (_: Any, _: Any) => NotUsed\n\n  def left[L, R]: (L, R) => L = _left.asInstanceOf[(L, R) => L]\n  def right[L, R]: (L, R) => R = _right.asInstanceOf[(L, R) => R]\n  def both[L, R]: (L, R) => (L, R) = _both.asInstanceOf[(L, R) => (L, R)]\n  def none[L, R]: (L, R) => NotUsed = _none.asInstanceOf[(L, R) => NotUsed]\n}\n下面代码，source的物化值保留了已读取文件的字符数，sink的物化值保存了实际入写文件的字节数。\nval source: Source[ByteString, Future[IOResult]] =\n  FileIO.fromPath(Paths.get(\"/tmp/file.txt\"))\nval sink: Sink[ByteString, Future[IOResult]] =\n  FileIO.toPath(Paths.get(\"/tmp/file2.txt\"))\nval graph: Source[ByteString, Future[IOResult]] = source // (1)\n  .via(Framing.delimiter(ByteString(\"\\n\"), 8192))\n  .filterNot(_.isEmpty)\n\nval readsF: Future[IOResult] = // (2)\n  graph.toMat(sink)(Keep.left).run() // Same: graph.to(sink).run()\nval writesF: Future[IOResult] = // (3)\n  graph.toMat(sink)(Keep.right).run() // Same: graph.runWith(sink)\nval (leftF, rightF) = graph.toMat(sink)(Keep.both).run() // (4)\nval notUsed: NotUsed = graph.toMat(sink)(Keep.none).run() // (5)\nSource上的via和所有转换操作（不带Mat的）默认都会保留 左边 的物化值，这样source的物化值（记录从文件已读取字节数）就作为graph的物化值被传递； graph被调用方作为 左边 ，参数sink作为 右边 ，Keep.left保留左边的物化值：记录从文件已读取字节数； graph被调用方作为 左边 ，参数sink作为 右边 ，Keep.right保留右边的物化值：记录已写入文件字节数； 通过Keep.both同时保留两边的物化值，作为一个 tuple 被返回； 不保留任何物化值。只在不需要关心流的任务结束和状态时使用。","title":"Keep"},{"location":"/streams/depth-flow.html","text":"","title":"深入 Flow"},{"location":"/streams/depth-flow.html#深入-flow","text":"TODO","title":"深入 Flow"},{"location":"/streams/depth-sink.html","text":"","title":"深入 Sink"},{"location":"/streams/depth-sink.html#深入-sink","text":"TODO","title":"深入 Sink"},{"location":"/streams/source.html","text":"","title":"创建 Source 的常用函数"},{"location":"/streams/source.html#创建-source-的常用函数","text":"","title":"创建 Source 的常用函数"},{"location":"/streams/source.html#frompublisher","text":"Source.fromPublisher[T](publisher: Publisher[T]): Source[T, NotUsed]\n从 Reactive Streams 的Publisher[T]接口生成一个Source，当于实现了 Reactive Streams 协议规范的流处理库、框架互进行操作时非常有用。","title":"fromPublisher"},{"location":"/streams/source.html#assubscriber","text":"Source.asSubscriber[T]: Source[T, Subscriber[T]]\n创建一个新的Source，它的物化值为Subscriber[T]，这样你可以调用Subscriber上的API来消费上游发送的数据。","title":"asSubscriber"},{"location":"/streams/source.html#fromiterator","text":"Source.fromIterator[T](f: () => Iterator[T]): Source[T, NotUsed]\n从一个Iterator 生成迭代器 创建Source，只有当下游调用pull函数请求时，上游（Source）才会生产数据，这里既才会调用Iterator的next方法生成整数。若迭代器不为空，则Source将一真可生成数据。如：Source.fromIterator(() => Iterator.from(0))，它将创建一个从数字0开始的无限源（Source）。","title":"fromIterator"},{"location":"/streams/source.html#cycle","text":"Source.cycle[T](f: () => Iterator[T]): Source[T, NotUsed]\n根据迭代器循环生成元素，下游可无限请求Source生成数据。","title":"cycle"},{"location":"/streams/source.html#fromgraph","text":"Source.fromGraph[T, M](g: Graph[SourceShape[T], M]): Source[T, M]\n从一个SourceShape图生成Source，当需要自定义实现一个Source时需要通过此函数将图转换成可使用的Source。","title":"fromGraph"},{"location":"/streams/source.html#apply","text":"Source.apply[T](iterable: immutable.Iterable[T]): Source[T, NotUsed]\n从一个有限可迭代的集合生成一个Source。","title":"apply"},{"location":"/streams/source.html#queue","text":"Source.queue[T](bufferSize: Int, overflowStrategy: OverflowStrategy):\n    Source[T, SourceQueueWithComplete[T]]\nbufferSize：设置队列最大可保存数据（若下游一直不pull数据） overflowStrategy：当队列满时的溢出策略\n创建一个队列源，它的物化值是一个队列，可通过此队列向Source传入指定类型的数据。\n示例代码：\nval (queue, result) = Source\n  .queue[Int](10, OverflowStrategy.dropNew)\n  .toMat(Sink.seq)(Keep.both)\n  .run()\nqueue.offer(10)\nqueue.offer(10)\nqueue.offer(10)\nqueue.complete()\nresult.futureValue should be(Seq(10, 10, 10))\nSource.tick[T](initialDelay: FiniteDuration, interval: FiniteDuration, tick: T): Source[T, Cancellable]： Source.single[T](element: T): Source[T, NotUsed]： Source.lazySingle[T](create: () => T): Source[T, NotUsed]： Source.unfold[S, E](s: S)(f: S => Option[(S, E)]): Source[E, NotUsed]： Source.unfoldAsync[S, E](s: S)(f: S => Future[Option[(S, E)]]): Source[E, NotUsed]： Source.unfoldResource[T, S](create: () => S, read: (S) => Option[T], close: (S) => Unit): Source[T, NotUsed]： unfoldResourceAsync[T, S]( create: () => Future[S], read: (S) => Future[Option[T]], close: (S) => Future[Done]): Source[T, NotUsed]： Source.repeat[T](element: T): Source[T, NotUsed]：repeat由unfold函数实现 Source.maybe[T]: Source[T, Promise[Option[T]]]： Source.future[T](futureElement: Future[T]): Source[T, NotUsed]： Source.lazyFuture[T](create: () => Future[T]): Source[T, NotUsed]： Source.futureSource[T, M](futureSource: Future[Source[T, M]]): Source[T, Future[M]]： Source.lazyFutureSource[T, M](create: () => Future[Source[T, M]]): Source[T, Future[M]]： Source.combine[T, U](first: Source[T, _], second: Source[T, _], rest: Source[T, _]*)( strategy: Int => Graph[UniformFanInShape[T, U], NotUsed]): Source[U, NotUsed]： Source.zipN[T](sources: immutable.Seq[Source[T, _]]): Source[immutable.Seq[T], NotUsed]： Source.zipWithN[T, O](zipper: immutable.Seq[T] => O)(sources: immutable.Seq[Source[T, _]]): Source[O, NotUsed]： Source.actorRef[T]( completionMatcher: PartialFunction[Any, CompletionStrategy], failureMatcher: PartialFunction[Any, Throwable], bufferSize: Int, overflowStrategy: OverflowStrategy): Source[T, ActorRef]：","title":"queue"},{"location":"/streams/flow.html","text":"","title":"执行转换的 Flow 常用函数"},{"location":"/streams/flow.html#执行转换的-flow-常用函数","text":"TODO","title":"执行转换的 Flow 常用函数"},{"location":"/streams/sink.html","text":"","title":"汇聚数据的 Sink 常用函数"},{"location":"/streams/sink.html#汇聚数据的-sink-常用函数","text":"TODO","title":"汇聚数据的 Sink 常用函数"},{"location":"/streams/group.html","text":"","title":"Streams 分组"},{"location":"/streams/group.html#streams-分组","text":"","title":"Streams 分组"},{"location":"/streams/group.html#grouped","text":"通过grouped函数可将上游发送的元素按指定个数分组，这在很场景下可作为一个优化策略。比如：批量写入数据库。\n\"grouped\" in {\n  val list = Source\n    .fromIterator(() => Iterator.from(0))\n    .grouped(100)\n    .take(2)\n    .runWith(Sink.seq)\n    .futureValue\n  list should be(Vector(0 until 100, 100 until 200))\n}","title":"grouped"},{"location":"/streams/group.html#groupedwithin","text":"若上游长时间没有元素被发送，很有可能下游将被永久的挂在那里，形成一种假死的状态。这时可通过groupedWithin函数传递一个超时时间，它将在指定的分组数量或超时时间两者之一达到时形成一个分组并将批量数据传给下游。\n\"groupedWithin\" in {\n  val f = Source\n    .fromIterator(() => Iterator.from(0))\n    .throttle(5, 500.millis)\n    .groupedWithin(100, 1.seconds)\n    .take(2)\n    .runWith(Sink.seq)\n  val list = Await.result(f, 3.seconds)\n  list should not be Vector(0 until 100, 100 until 200)\n}","title":"groupedWithin"},{"location":"/streams/throttle.html","text":"","title":"基于时间的处理"},{"location":"/streams/throttle.html#基于时间的处理","text":"很多时候我们都想限制上游发送元素到下游的（生产）速度，Akka Streams内建了对此的支持。通过Flow.throttle的各个版本提供了多种策略的限流功能。\nSource\n  .fromIterator(() => Iterator.from(0))\n  .throttle(5, 500.millis)\nthrottle限制每500毫秒内最多只生产5个元素（可发送5个到下游）。","title":"基于时间的处理"},{"location":"/streams/file.html","text":"","title":"访问文件"},{"location":"/streams/file.html#访问文件","text":"Akka Streams内置了 FileIO 工具库，可对文件以流的方式进行读、写。\nFileIO提供了toPath和fromPath两个函数。toPath是一个Sink，它接收上游流过来的元素（ByteString）并将其写入（追加）文件；fromPath是一个Source，它将按下游的（要求）从文件读取数据。\nprivate val LINE_SEPARATOR = ByteString(\"\\n\")\nprivate val file = Files.createTempFile(\"cookbook\", \"txt\")\nprivate val TAKE_SIZE = 100","title":"访问文件"},{"location":"/streams/file.html#fileio-topath-写数据到文件","text":"这里构造了0到99（包含）个数字，并按一行一个的方式写入文件。\nval f = Source\n  .fromIterator(() => Iterator.from(0))\n  .map(n => ByteString(n.toString))\n  .take(TAKE_SIZE)\n  .intersperse(ByteString.empty, LINE_SEPARATOR, LINE_SEPARATOR)\n  .runWith(FileIO.toPath(file))\nval ioResult = f.futureValue\nioResult.count should be > 0L\nintersperse转换函数接受3个参数，分别在流开始前、每个元素后、流结束后添加一个指定值，就类型集合类型上的mkString(start: String, sep: String, end: String): String函数一样。这里通过此函数实现了在每写一个元素后将换行符也写入文件功能。\n其实也可以在map(n => ByteString(n.toString))将数字转换成字符串时直接把换行符给附加上去，就像这样：map(n => ByteString(n.toString) ++ LINE_SEPARATOR)。\nWarning 需要注意Source.repeat(....).take(....)这里的take函数，在这个例子里是不可或缺的，若忘记限制repeat流的长度，则整个流将无限调用下去，直到写满你的磁盘。 当然，在这里会被futureValue的超时异常而终止测试的执行，最终很有可能不会写满你的磁盘。\nFileIO.toPath在多个重载版本，在以未指定options参数时方式调用时，options的默认值为：Set(WRITE, TRUNCATE_EXISTING, CREATE)，它以写入的方式打开文件，同时若文件已存在则清空内容，不存在则创建。toPath完整版本函数签名如下，startPosition指定了写入指针的初始偏移量（字节）：\ndef toPath(f: Path, options: Set[OpenOption], startPosition: Long): Sink[ByteString, Future[IOResult]]","title":"FileIO.toPath 写数据到文件"},{"location":"/streams/file.html#fileio-frompath-从文件读数据","text":"使用Framing.delimiter按指定的分隔标准从文件流读取数据（元素）。\nval f = FileIO\n  .fromPath(file)\n  .via(Framing.delimiter(LINE_SEPARATOR, 8192))\n  .filterNot(_.isEmpty)\n  .map(bytes => bytes.utf8String.toInt)\n  .runWith(Sink.seq)\nval ints = f.futureValue\nints should be(0 until 100)\nFileIO.fromPath也有重载版本，其完整版本函数签名如下：\ndef fromPath(f: Path, chunkSize: Int, startPosition: Long): Source[ByteString, Future[IOResult]]\nchunkSize：每次从文件里指定字节的块（缓冲）大小（字节） startPosition：指定读取指针偏移量（字节）\nWarning 使用Framing.delimiter从文件流里读取数据时需要注意一个问题，若文件不以你指定的分隔值结尾将会抛出异常：Caused by: akka.stream.scaladsl.Framing$FramingException: Stream finished but there was a truncated final frame in the buffer。当流读到文件末尾还未能找到指定的分隔值而不能结束分帧（framing）操作，而这时上游已经发送了完成（ Finish ）信号，而Framing还有未完成的buffer则会抛出此异常。 你将intersperse的第3个参数指定为ByteString.empty再次运行测试，就可重现这个问题。","title":"FileIO.fromPath 从文件读数据"},{"location":"/streams/ftp.html","text":"","title":"访问FTP/sFTP"},{"location":"/streams/ftp.html#访问ftp-sftp","text":"TODO","title":"访问FTP/sFTP"},{"location":"/streams/custom-graph.html","text":"","title":"自定义图（Graph）"},{"location":"/streams/custom-graph.html#自定义图-graph-","text":"TODO","title":"自定义图（Graph）"},{"location":"/storage/index.html","text":"","title":"访问存储"},{"location":"/storage/index.html#访问存储","text":"使用JDBC访问关系数据库 访问 Cassandra 访问 MongoDB 访问 Elasticsearch","title":"访问存储"},{"location":"/storage/jdbc.html","text":"","title":"使用JDBC访问关系数据库"},{"location":"/storage/jdbc.html#使用jdbc访问关系数据库","text":"TODO","title":"使用JDBC访问关系数据库"},{"location":"/storage/cassandra.html","text":"","title":"访问 Cassandra"},{"location":"/storage/cassandra.html#访问-cassandra","text":"TODO","title":"访问 Cassandra"},{"location":"/storage/mongodb.html","text":"","title":"访问 MongoDB"},{"location":"/storage/mongodb.html#访问-mongodb","text":"TODO","title":"访问 MongoDB"},{"location":"/storage/elasticsearch.html","text":"","title":"访问 Elasticsearch"},{"location":"/storage/elasticsearch.html#访问-elasticsearch","text":"TODO","title":"访问 Elasticsearch"},{"location":"/integration/index.html","text":"","title":"集成"},{"location":"/integration/index.html#集成","text":"将Akka与第3方框架、应该集成。\n在 Spring 里使用 Akka Streams 添加 Akka Streams 支持 编写控制器 运行程序","title":"集成"},{"location":"/integration/spring-web.html","text":"","title":"在 Spring 里使用 Akka Streams"},{"location":"/integration/spring-web.html#在-spring-里使用-akka-streams","text":"Akka Streams 作为 Reactive Streams 的一种实现，可以很方便的与其它 Reactive Streams 实现进行互操作。而从 Spring 5 开始，也提供了 Reactive Streams 实现的版本： WebFlow 。 Alpakka Spring Web 项目提供了对Spring Boot的支持，可以让我们在 Spring 项目中使用 Akka Streams。","title":"在 Spring 里使用 Akka Streams"},{"location":"/integration/spring-web.html#添加-akka-streams-支持","text":"需要给Spring项目添加 Akka Streams 依赖：\nsbt libraryDependencies += \"com.lightbend.akka\" %% \"akka-stream-alpakka-spring-web\" % \"2.0.0-M1\" Maven <dependency>\n  <groupId>com.lightbend.akka</groupId>\n  <artifactId>akka-stream-alpakka-spring-web_2.13</artifactId>\n  <version>2.0.0-M1</version>\n</dependency> Gradle dependencies {\n  compile group: 'com.lightbend.akka', name: 'akka-stream-alpakka-spring-web_2.13', version: '2.0.0-M1'\n}","title":"添加 Akka Streams 支持"},{"location":"/integration/spring-web.html#编写控制器","text":"在添加了 Akka Streams 支持后，我们就可以在控制器代码里直接返回 Source[T, Mat] 类型的结果了。\nimport akka.NotUsed;\nimport akka.stream.javadsl.Source;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class SampleController {\n  @RequestMapping(\"/\")\n  public Source<String, NotUsed> index() {\n    return Source.repeat(\"Hello world!\").intersperse(\"\\n\").take(10);\n  }\n}","title":"编写控制器"},{"location":"/integration/spring-web.html#运行程序","text":"SampleApplication.java 代码如下，如通常的Spring Boot程序并无起二致。\n@SpringBootApplication\npublic class SampleApplication {\n  public static void main(String[] args) {\n    SpringApplication.run(SampleApplication.class, args);\n  }\n}\n运行 SampleApplication 启动Spring Web程序，通过curl访问服务示例如下：\n$ curl -i http://localhost:8080\nHTTP/1.1 200 \nContent-Type: text/plain\nTransfer-Encoding: chunked\nDate: Wed, 20 Nov 2019 03:47:44 GMT\n\nHello world!\nHello world!\nHello world!\nHello world!\nHello world!\n可以看到响应头里有：Transfer-Encoding: chunked，这个结果是以流的形式将数据一块一块返回的。","title":"运行程序"},{"location":"/http/index.html","text":"","title":"Akka HTTP"},{"location":"/http/index.html#akka-http","text":"请访问外部链接阅读： 《Scala Web 开发——基于 Akka HTTP》 。","title":"Akka HTTP"},{"location":"/grpc/index.html","text":"","title":"Akka gRPC"},{"location":"/grpc/index.html#akka-grpc","text":"gRPC使用Protobuf进行数据序列化，基于HTTP 2提供RPC通信。具有快速、高效、易用、可扩展等特点。采用HTTP 2作为底层协议，可以更好的与已有的HTTP基础服务整合，简化了运维管理（不需要为了RPC单独开放网络端口，并对其进行管理）。gRPC支持请求/响应和Stream多种接口形式，可以实现服务端推送功能。\nAkka提供了开箱即用的 akka-grpc，从编译、构建、发布……与Scala/Akka生态完美整合。Why gRPC 这篇文章详细的说明了为什么需要gRPC，特别是gRPC与REST、SOAP、Message Bus和Akka Remoting的区别，阐述的简明扼要。\ngRPC服务 定义消息和服务 实现 gRPC 服务 测试 gRPC 服务 构建工具 sbt 配置 目录结构 部署 sbt-assembly sbt-native-packager PowerApi 小结","title":"Akka gRPC"},{"location":"/grpc/grpc.html","text":"","title":"gRPC服务"},{"location":"/grpc/grpc.html#grpc服务","text":"","title":"gRPC服务"},{"location":"/grpc/grpc.html#定义消息和服务","text":"syntax = \"proto3\";\n\noption java_multiple_files = true;\n\npackage greeter;\n\nmessage HelloRequest {\n    string name = 1;\n}\n\nmessage HelloReply {\n    string message = 1;\n}\n\nservice GreeterService {\n    // req-resp\n    rpc SayHello (HelloRequest) returns (HelloReply) {}\n\n    // keep requests\n    rpc ItKeepsTalking (stream HelloRequest) returns (HelloReply) {}\n\n    // keep responses\n    rpc ItKeepsReplying (HelloRequest) returns (stream HelloReply) {}\n\n    // keep requests & responses\n    rpc StreamHellos (stream HelloRequest) returns (stream HelloReply) {}\n}\n这里定义了两个消息：HelloRequest、HelloReply和GreeterService服务，GreeterService定义了4个服务方法，分别是：\nSayHello：经典的请求-响应服务，发送一个请求获得一个响应； ItKeepsTalking：持续不断的发送多个请求，在请求停止后获得一个响应； ItKeepsReplying：发送一个请求，获得持续不断的多个响应； StreamHelloes：持续不断的发送响应的同时也可获得持续不断的响应，可以通过Source.queue来获得可发送数据的Queue和获得响应数据的Source。","title":"定义消息和服务"},{"location":"/grpc/grpc.html#实现-grpc-服务","text":"class GreeterServiceImpl()(implicit system: ActorSystem[_]) extends GreeterService {\n  import system.executionContext\n\n  override def sayHello(in: HelloRequest): Future[HelloReply] = {\n    Future.successful(HelloReply(s\"Hello, ${in.name}.\"))\n  }\n\n  override def itKeepsTalking(\n      in: Source[HelloRequest, NotUsed]): Future[HelloReply] = {\n    in.runWith(Sink.seq)\n      .map(ins => HelloReply(\"Hello, \" + ins.map(_.name).mkString(\"\", \", \", \".\")))\n  }\n\n  override def itKeepsReplying(in: HelloRequest): Source[HelloReply, NotUsed] = {\n    Source\n      .fromIterator(() => Iterator.from(1))\n      .map(n => HelloReply(s\"Hello, ${in.name}; this is $n times.\"))\n  }\n\n  override def streamHellos(\n      ins: Source[HelloRequest, NotUsed]): Source[HelloReply, NotUsed] = {\n    ins.map(in => HelloReply(s\"Hello, ${in.name}.\"))\n  }\n}\nAkka gRPC提供了基于 Akka Streams 的API，更多 Akka Streams 的内容请参阅： Akka 流（Streams）。","title":"实现 gRPC 服务"},{"location":"/grpc/grpc.html#测试-grpc-服务","text":"通过 Scalatest 对实现的4个gRPC服务进行测试，下面是单元测试代码：\n\"sayHello\" in {\n  greeterClient.sayHello(HelloRequest(\"Scala\")).futureValue should ===(\n    HelloReply(\"Hello, Scala.\"))\n}\n\n\"itKeepsReplying\" in {\n  greeterClient\n    .itKeepsReplying(HelloRequest(\"Scala\"))\n    .take(5)\n    .runWith(Sink.seq)\n    .futureValue should ===(\n    Seq(\n      HelloReply(\"Hello, Scala; this is 1 times.\"),\n      HelloReply(\"Hello, Scala; this is 2 times.\"),\n      HelloReply(\"Hello, Scala; this is 3 times.\"),\n      HelloReply(\"Hello, Scala; this is 4 times.\"),\n      HelloReply(\"Hello, Scala; this is 5 times.\")))\n}\n\n\"itKeepsTalking\" in {\n  val (queue, in) =\n    Source\n      .queue[HelloRequest](16, OverflowStrategy.backpressure)\n      .preMaterialize()\n  val f = greeterClient.itKeepsTalking(in)\n  Seq(\"Scala\", \"Java\", \"Groovy\", \"Kotlin\").foreach(program =>\n    queue.offer(HelloRequest(program)))\n  TimeUnit.SECONDS.sleep(1)\n  queue.complete()\n  f.futureValue should ===(HelloReply(\"Hello, Scala, Java, Groovy, Kotlin.\"))\n}\n\n\"streamHellos\" in {\n  val (queue, in) =\n    Source\n      .queue[HelloRequest](16, OverflowStrategy.backpressure)\n      .preMaterialize()\n  val f = greeterClient.streamHellos(in).runWith(Sink.seq)\n  Seq(\"Scala\", \"Java\", \"Groovy\", \"Kotlin\").foreach(item =>\n    queue.offer(HelloRequest(item)))\n  TimeUnit.SECONDS.sleep(1)\n  queue.complete()\n  f.futureValue should ===(\n    Seq(\n      HelloReply(\"Hello, Scala.\"),\n      HelloReply(\"Hello, Java.\"),\n      HelloReply(\"Hello, Groovy.\"),\n      HelloReply(\"Hello, Kotlin.\")))\n}\n在运行测试前需要先启动gRPC服务，在 Scalatest 的beforeAll函数内启动gRPC HTTP 2服务：\noverride protected def beforeAll(): Unit = {\n  super.beforeAll()\n  val handler = GreeterServiceHandler(new GreeterServiceImpl())\n  Http().bindAndHandleAsync(handler, \"localhost\", 8000)\n  greeterClient = GreeterServiceClient(\n    GrpcClientSettings.fromConfig(GreeterService.name))\n}\n在构造 GreeterServiceClient gRCP客户端时需要提供GrpcClientSettings设置选项，这里通过调用fromConfig函数来从 HOCON 配置文件里读取gRPC服务选项，相应的application-test.conf配置文件内容如下：\nakka.http.server.preview.enable-http2 = on\nakka.grpc.client {\n  \"greeter.GreeterService\" {\n    host = \"localhost\"\n    port = 8000\n    use-tls = false\n  }\n}\n其中use-tls设置gRPC客户端不使用HTTPs建立连接，因为我们这个单元测试启动的gRPC HTTP服务不未启动SSL/TLS。","title":"测试 gRPC 服务"},{"location":"/grpc/build-tool.html","text":"","title":"构建工具"},{"location":"/grpc/build-tool.html#构建工具","text":"","title":"构建工具"},{"location":"/grpc/build-tool.html#sbt-配置","text":"project\n  .in(file(\"grpc\"))\n  .enablePlugins(AkkaGrpcPlugin, JavaAgent)\n  .settings(\n    javaAgents += \"org.mortbay.jetty.alpn\" % \"jetty-alpn-agent\" % \"2.0.9\" % \"runtime;test\",\n    libraryDependencies ++= Seq(\n        \"com.thesamet.scalapb\" %% \"scalapb-runtime\" % scalapb.compiler.Version.scalapbVersion % \"protobuf\"))\n要使工程支持 Akka gRPC，需要在sbt项目里启用AkkaGrpcPlugin插件，若需要在sbt里测试gRPC服务，还需要同时启用JavaAgent插件。\njetty-alpn-agent提供Akka HTTP 2需要的 ALPN 支持，使用 javaAgents 配置项使它在runtime和test两个执行范围可用。\n当你需要在代码中引用google.proto或scalapb.proto定义的消息Protobuf类型时，需要引入scalapb-runtime库依赖。","title":"sbt 配置"},{"location":"/grpc/build-tool.html#目录结构","text":"在一个 sbt 目录结构里，通过定义.proto定义的Protobuf消息和gRPC服务需要放在protobuf（或proto）目录，如下面目录结构：\n├── src\n│   ├── main\n│   │   ├── protobuf\n│   │   ├── resources\n│   │   └── scala\n│   └── test\n│       ├── resources\n│       └── scala\n通过.proto定义的消息类型和gRPC服务，会在sbt的托管源码路径下生成相应的消息case class、服务接口和客户端实现：\n└── target\n    ├── scala-2.13\n    │   ├── src_managed\n    │   │   └── main\n    │   │       ├── greeter\n    │   │       │   ├── GreeterProto.scala\n    │   │       │   ├── GreeterServiceClient.scala\n    │   │       │   ├── GreeterServiceHandler.scala\n    │   │       │   ├── GreeterService.scala\n    │   │       │   ├── HelloReply.scala\n    │   │       │   └── HelloRequest.scala","title":"目录结构"},{"location":"/grpc/deployment.html","text":"","title":"部署"},{"location":"/grpc/deployment.html#部署","text":"","title":"部署"},{"location":"/grpc/deployment.html#sbt-assembly","text":"","title":"sbt-assembly"},{"location":"/grpc/deployment.html#构建","text":"使用sbt-assembly可以把程序打包成一个单一的jar包发布，需要在sbt插件配置（project/plugins.sbt）添加发下插件：\naddSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"0.14.9\")\n然后在sbt项目的settings中添加如下设置：\nmainClass in assembly := Some(\"greeter.GreeterApplication\"),\ntest in assembly := {},\nassemblyMergeStrategy in assembly := {\n  case PathList(\"io\", \"netty\", xs @ _*)               => MergeStrategy.first\n  case PathList(\"google\", \"protobuf\", xs @ _*)        => MergeStrategy.first\n  case PathList(\"com\", \"google\", \"protobuf\", xs @ _*) => MergeStrategy.first\n  case PathList(\"scalapb\", xs @ _*)                   => MergeStrategy.first\n  case \"application.conf\"                             => MergeStrategy.concat\n  case \"reference.conf\"                               => MergeStrategy.concat\n  case \"module-info.class\"                            => MergeStrategy.concat\n  case \"META-INF/io.netty.versions.properties\"        => MergeStrategy.first\n  case \"META-INF/native/libnetty-transport-native-epoll.so\" =>\n    MergeStrategy.first\n  case n if n.endsWith(\".txt\")   => MergeStrategy.concat\n  case n if n.endsWith(\"NOTICE\") => MergeStrategy.concat\n  case x =>\n    val oldStrategy = (assemblyMergeStrategy in assembly).value\n    oldStrategy(x)\n}\nmainClass指定当通过java -jar assembly.jar命令运行jar包时，默认的启动类（启动类必须有main函数）。\n因为是将所有源码和依赖打到一个jar包，所以需要配置assemblyMergeStrategy来决定当文件名起冲突时的合并策略。\nassembly\n通过在sbt shell执行assembly命令，即可生成可运行的jar包。\n> grpc/assembly\n[info] Strategy 'concat' was applied to 2 files (Run the task at debug level to see details)\n[info] Strategy 'deduplicate' was applied to 667 files (Run the task at debug level to see details)\n[info] Strategy 'discard' was applied to 89 files (Run the task at debug level to see details)\n[info] Strategy 'filterDistinctLines' was applied to 2 files (Run the task at debug level to see details)\n[info] Strategy 'first' was applied to 337 files (Run the task at debug level to see details)\n[info] Assembly up to date: /home/yangjing/workspace/scala-web-development/grpc/target/scala-2.13/grpc-assembly-1.0.0.jar\n[success] Total time: 3 s, completed Nov 24, 2019 6:24:09 PM","title":"构建"},{"location":"/grpc/deployment.html#运行","text":"通过java -jar命令运行gprc-assembly-1.0.0.jar时，需要提供 jetty-alpn-agent Agent，可以在此下载 jetty-alpn-agent：\nwget -c https://repo1.maven.org/maven2/org/mortbay/jetty/alpn/jetty-alpn-agent/2.0.9/jetty-alpn-agent-2.0.9.jar\n即可使用如下命令启动gRPC服务：\njava -javaagent:jetty-alpn-agent-2.0.9.jar -jar grpc-assembly-1.0.0.jar\n看到类似如下输出，则代表Greeter gRPC服务已启动：\n18:37:04.221 [grpc-akka.actor.default-dispatcher-3] INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started\n18:37:05.093 [grpc-akka.actor.default-dispatcher-5] INFO greeter.GreeterApplication$ - Greeter gRPC server started, bind to ServerBinding(/127.0.0.1:8000).","title":"运行"},{"location":"/grpc/deployment.html#sbt-native-packager","text":"","title":"sbt-native-packager"},{"location":"/grpc/deployment.html#配置","text":"需要添加sbt-native-packager sbt插件并启动JavaAppPackaging插件：\nproject/plugins.sbt\naddSbtPlugin(\"com.typesafe.sbt\" % \"sbt-native-packager\" % \"1.4.1\")\nsbt项目配置\nenablePlugins(JavaAppPackaging)\nmainClass设置选项在 sbt-native-packager 里也是需要的，它指定了程序运行时执行的主类。\n使用 sbt-native-packager 进行程序打包，运行时不需要再手动指定 -javaagent，它会在生成的启动脚本里根据sbt的javaAgents配置项设置后相应的启动命令行参数。","title":"配置"},{"location":"/grpc/deployment.html#打包","text":"","title":"打包"},{"location":"/grpc/deployment.html#dist","text":"使用dist命令即可在sbt shell类打包：\n> grpc/dist\n....\n[success] All package validations passed\n[info] Your package is ready in /home/yangjing/workspace/scala-web-development/grpc/target/universal/grpc-1.0.0.zip\n[success] Total time: 12 s, completed Nov 24, 2019 6:45:55 PM\n它将生成一个zip压缩包grpc-1.0.0.zip在项目的target/universal目录，将压缩包上传到服务器上脚本后执行bin目录里的启动脚本（启动脚本的名字默认为项目名）即可运行程序了。","title":"dist"},{"location":"/grpc/deployment.html#stage","text":"你也可以执行stage命令生成完整的包文件路径，而不是生成一个压缩包。stage命令运行后文件路径为：target/universal/stage。\n> grpc/stage\nstage 目录结构类似：\n├── bin\n│   ├── grpc\n│   └── grpc.bat\n├── jetty-alpn-agent\n│   └── jetty-alpn-agent-2.0.9.jar\n└── lib\n    ├── ch.qos.logback.logback-classic-1.2.3.jar\n    ├── ch.qos.logback.logback-core-1.2.3.jar\n    ├── com.fasterxml.jackson.core.jackson-annotations-2.10.0.jar\n    ├── ....","title":"stage"},{"location":"/grpc/power-api.html","text":"","title":"PowerApi"},{"location":"/grpc/power-api.html#powerapi","text":"Akka gRPC是基于Akka HTTP实现的，怎样才可以访问HTTP Header呢？我们基于HTTP Header可以实现一些增强功能，比如： 调用链跟踪、 认证 、 鉴权 等。这非常的简单，在sbt配置里添加akkaGrpcCodeGeneratorSettings += \"server_power_apis\"即可，这样生成的Akka gRPC自动生成的代码会额外提供XxxxPowerApi结尾的服务接口。\ntrait GreeterServicePowerApi extends GreeterService {\n  \n  def sayHello(\n    in: greeter.HelloRequest,\n    metadata: Metadata): scala.concurrent.Future[greeter.HelloReply]\n  \n  def itKeepsTalking(\n    in: akka.stream.scaladsl.Source[greeter.HelloRequest, akka.NotUsed],\n    metadata: Metadata): scala.concurrent.Future[greeter.HelloReply]\n  \n  def itKeepsReplying(\n    in: greeter.HelloRequest,\n    metadata: Metadata): akka.stream.scaladsl.Source[greeter.HelloReply, akka.NotUsed]\n  \n  def streamHellos(\n    in: akka.stream.scaladsl.Source[greeter.HelloRequest, akka.NotUsed],\n    metadata: Metadata): akka.stream.scaladsl.Source[greeter.HelloReply, akka.NotUsed]\n  \n  override def sayHello(in: greeter.HelloRequest): scala.concurrent.Future[greeter.HelloReply] = throw new GrpcServiceException(Status.UNIMPLEMENTED)\n  \n  override def itKeepsTalking(in: akka.stream.scaladsl.Source[greeter.HelloRequest, akka.NotUsed]): scala.concurrent.Future[greeter.HelloReply] = throw new GrpcServiceException(Status.UNIMPLEMENTED)\n  \n  override def itKeepsReplying(in: greeter.HelloRequest): akka.stream.scaladsl.Source[greeter.HelloReply, akka.NotUsed] = throw new GrpcServiceException(Status.UNIMPLEMENTED)\n  \n  override def streamHellos(in: akka.stream.scaladsl.Source[greeter.HelloRequest, akka.NotUsed]): akka.stream.scaladsl.Source[greeter.HelloReply, akka.NotUsed] = throw new GrpcServiceException(Status.UNIMPLEMENTED)\n}\n可以看到生成了GreeterServicePowerApi接口，它继承了GreeterService，并且默认的4个服务都已经有了默认实现：throw new GrpcServiceException(Status.UNIMPLEMENTED)；取而代之的是4个新的重载函数，它们都多了一个Metadata参数。Metadata接口定义如下：\n@DoNotInherit trait Metadata {\n  def getText(key: String): Option[String]\n  def getBinary(key: String): Option[ByteString]\n  def asMap: Map[String, List[MetadataEntry]]\n}\n\nclass MetadataImpl(headers: immutable.Seq[HttpHeader] = immutable.Seq.empty) extends Metadata {\n  // ....\n}\n其实Metadata保存的就是HTTP Header，通过它的实现类MetadataImpl构造函数需要HttpHeader列表来初始化既可看出。它提供了getText、getBinary和asMap方法提供了gRPC服务元数据（HTTP Header）的访问接口。\n通过Akka gRPC生成的服务句柄类（GreeterServicePowerApiHandler），可以清晰的知道Akka gRPC是怎么创建Metadata的。\ndef partial(\n    implementation: GreeterServicePowerApi,\n    prefix: String = GreeterService.name,\n    eHandler: ActorSystem => PartialFunction[Throwable, io.grpc.Status] = GrpcExceptionHandler.defaultMapper\n  )(implicit mat: Materializer, system: ActorSystem): PartialFunction[HttpRequest, scala.concurrent.Future[HttpResponse]] = {\n  implicit val ec: ExecutionContext = mat.executionContext\n  import GreeterService.Serializers._\n\n  def handle(request: HttpRequest, method: String): scala.concurrent.Future[HttpResponse] = method match {\n    case \"SayHello\" =>\n      val responseCodec = Codecs.negotiate(request)\n      val metadata = new MetadataImpl(request.headers)\n      GrpcMarshalling.unmarshal(request)(HelloRequestSerializer, mat)\n        .flatMap(implementation.sayHello(_, metadata))\n        .map(e => GrpcMarshalling.marshal(e, eHandler)(HelloReplySerializer, mat, responseCodec, system))\n    \n    case \"ItKeepsTalking\" =>\n     // ....\n  }\n  // ....\n}\ncase \"SayHello\" =>模式匹配既是构造Metadata和执行SayHellogRPC服务的代码逻辑。val metadata = new MetadataImpl(request.headers)一行代码通过request.headers构造了MetadataImpl对象。","title":"PowerApi"},{"location":"/grpc/grpc.z.html","text":"","title":"小结"},{"location":"/grpc/grpc.z.html#小结","text":"官方文档和源码是最好的学习资源：\n文档：https://doc.akka.io/docs/akka-grpc/ 源码：https://github.com/akka/akka-grpc\nNote 有关Akka HTTP的更多内容可阅读作者写的另一本开源电子书： 《Scala Web开发》 。","title":"小结"},{"location":"/cluster/index.html","text":"","title":"Akka 集群"},{"location":"/cluster/index.html#akka-集群","text":"使用Jackson作为序列化","title":"Akka 集群"},{"location":"/cluster/serialization-jackson.html","text":"","title":"使用Jackson作为序列化"},{"location":"/cluster/serialization-jackson.html#使用jackson作为序列化","text":"","title":"使用Jackson作为序列化"},{"location":"/persistence/index.html","text":"","title":"Akka 持久化"},{"location":"/persistence/index.html#akka-持久化","text":"","title":"Akka 持久化"}]}